# üöÄ Guia de Integra√ß√£o: Componentes RAG2 ‚Üí Verba

Este guia mostra como integrar os componentes de alto valor copiados do RAG2 para o Verba.

---

## üìã Componentes Dispon√≠veis

1. ‚úÖ **TelemetryMiddleware** - Observabilidade de API
2. ‚úÖ **Embeddings Cache** - Cache de embeddings
3. ‚úÖ **Telemetry Collector** - M√©tricas de ETL
4. ‚úÖ **UUID Determin√≠stico** - Idempot√™ncia
5. ‚úÖ **Text Preprocessing** - Normaliza√ß√£o de texto
6. ‚úÖ **Quality Scoring** - Filtro de qualidade

---

## 1. TelemetryMiddleware (Observabilidade)

### O que faz
Middleware FastAPI que registra lat√™ncia, contagem de requests e erros por endpoint.

### Como integrar

**Passo 1**: Adicionar middleware em `goldenverba/server/api.py`:

```python
from verba_extensions.middleware.telemetry import TelemetryMiddleware

# Adicionar ANTES de outras rotas
app.add_middleware(TelemetryMiddleware, enable_logging=True)
```

**Passo 2**: Adicionar endpoint para stats (opcional):

```python
from verba_extensions.middleware.telemetry import TelemetryMiddleware

@app.get("/api/telemetry/stats")
async def get_telemetry_stats():
    """Retorna estat√≠sticas de telemetria da API"""
    return TelemetryMiddleware.get_shared_stats()

@app.get("/api/telemetry/slo")
async def check_slo(threshold_ms: float = 350.0):
    """Verifica se SLO est√° sendo atendido"""
    is_ok, details = TelemetryMiddleware.check_shared_slo(threshold_ms)
    return {
        "is_ok": is_ok,
        **details
    }
```

### Resultado
- Logs estruturados em JSON para cada request
- M√©tricas de lat√™ncia (p50, p95, p99)
- Estat√≠sticas por endpoint
- SLO checking autom√°tico

---

## 2. Embeddings Cache (Performance)

### O que faz
Cache in-memory determin√≠stico de embeddings para evitar re-embedding redundante.

### Como integrar

**Passo 1**: Importar em embedders (ex: `goldenverba/components/embedding/OpenAIEmbedder.py`):

```python
from verba_extensions.utils.embeddings_cache import (
    get_cached_embedding,
    get_cache_key,
    get_cache_stats
)
```

**Passo 2**: Usar cache antes de chamar API de embedding:

```python
def embed(self, documents, client, logging):
    # ... c√≥digo existente ...
    
    for doc in documents:
        for chunk in doc.chunks:
            # Gera chave de cache
            cache_key = get_cache_key(
                text=chunk.text,
                doc_uuid=str(doc.uuid),
                parent_type="chunk"
            )
            
            # Obt√©m embedding com cache
            embedding, was_cached = get_cached_embedding(
                text=chunk.text,
                cache_key=cache_key,
                embed_fn=lambda t: self._call_openai_api(t)  # Sua fun√ß√£o de embedding
            )
            
            # Usa embedding normalmente
            # ... resto do c√≥digo ...
```

**Passo 3** (Opcional): Adicionar endpoint para stats:

```python
from verba_extensions.utils.embeddings_cache import get_cache_stats

@app.get("/api/embeddings/cache/stats")
async def get_embeddings_cache_stats():
    """Retorna estat√≠sticas do cache de embeddings"""
    return get_cache_stats()
```

### Resultado
- Redu√ß√£o de chamadas de embedding (especialmente em re-uploads)
- Economia de custo de APIs
- Melhor performance

---

## 3. Telemetry Collector (M√©tricas ETL)

### O que faz
Coleta m√©tricas de normaliza√ß√£o e cobertura para identificar gaps e melhorias.

### Como integrar

**Passo 1**: Usar em plugins de ETL (ex: `verba_extensions/plugins/llm_metadata_extractor.py`):

```python
from verba_extensions.utils.telemetry import get_telemetry

telemetry = get_telemetry()

# Ao normalizar t√≠tulo
telemetry.record_title_normalization(
    method="regex",  # ou "llm", "none", etc.
    original_title="CEO"
)

# Ao normalizar skill
telemetry.record_skill_normalization(
    was_mapped=True,
    original_skill="Python"
)

# Ao filtrar chunk por qualidade
telemetry.record_chunk_filtered_by_quality(
    parent_type="section",
    score=0.25,
    reason="LEN_V_SHORT:DENSITY_LOW"
)
```

**Passo 2**: Adicionar endpoint para relat√≥rio:

```python
from verba_extensions.utils.telemetry import get_telemetry

@app.get("/api/etl/telemetry")
async def get_etl_telemetry():
    """Retorna relat√≥rio de telemetria de ETL"""
    return get_telemetry().generate_report()

@app.post("/api/etl/telemetry/reset")
async def reset_etl_telemetry():
    """Reseta coletor de telemetria"""
    get_telemetry().reset()
    return {"status": "reset"}
```

### Resultado
- Identifica√ß√£o de gaps em normaliza√ß√£o
- M√©tricas de cobertura
- Relat√≥rios JSON para an√°lise

---

## 4. UUID Determin√≠stico (Idempot√™ncia)

### O que faz
Gera UUIDs determin√≠sticos (UUID v5) para garantir idempot√™ncia em re-uploads.

### Como integrar

**Passo 1**: Usar em import de documentos:

```python
from verba_extensions.utils.uuid import generate_doc_uuid, generate_chunk_uuid

# Ao importar documento
doc_uuid = generate_doc_uuid(
    source_url=document.meta.get("source_url"),
    public_identifier=document.meta.get("public_id"),
    title=document.title
)

# Ao criar chunks
chunk_uuid = generate_chunk_uuid(
    doc_uuid=doc_uuid,
    chunk_id=f"{doc_uuid}:{chunk.chunk_id}"
)
```

**Resultado**
- Re-uploads n√£o criam duplicatas
- Upsert seguro
- Idempot√™ncia garantida

---

## 5. Text Preprocessing (Consist√™ncia)

### O que faz
Normaliza texto antes de embedding para garantir consist√™ncia.

### Como integrar

**Passo 1**: Usar antes de embedding:

```python
from verba_extensions.utils.preprocess import prepare_for_embedding

# Antes de embed
text_for_embedding = prepare_for_embedding(chunk.text)

# Garante que texto embeddado = texto armazenado
assert chunk.text == text_for_embedding

# Agora faz embedding
embedding = embedder.embed(text_for_embedding)
```

**Resultado**
- Consist√™ncia entre texto armazenado e embeddado
- Melhor qualidade de embeddings

---

## 6. Quality Scoring (Filtro de Qualidade)

### O que faz
Calcula score de qualidade de chunks para filtrar conte√∫do de baixa qualidade.

### Como integrar

**Passo 1**: Usar em chunkers ou filtros:

```python
from verba_extensions.utils.quality import compute_quality_score

# Ao processar chunk
score, reason = compute_quality_score(
    text=chunk.text,
    parent_type=chunk.meta.get("parent_type"),
    is_summary=chunk.meta.get("is_summary", False)
)

# Filtrar chunks de baixa qualidade
if score < 0.3:  # Threshold configur√°vel
    # Opcional: registrar na telemetria
    from verba_extensions.utils.telemetry import get_telemetry
    get_telemetry().record_chunk_filtered_by_quality(
        parent_type=chunk.meta.get("parent_type", "unknown"),
        score=score,
        reason=reason
    )
    continue  # Pula chunk
```

**Resultado**
- Filtragem autom√°tica de conte√∫do de baixa qualidade
- Melhor qualidade de resultados de busca

---

## üìä Exemplo de Integra√ß√£o Completa

### `goldenverba/server/api.py`:

```python
from fastapi import FastAPI
from verba_extensions.middleware.telemetry import TelemetryMiddleware

app = FastAPI()

# Middleware de telemetria
app.add_middleware(TelemetryMiddleware, enable_logging=True)

# Endpoints de telemetria
@app.get("/api/telemetry/stats")
async def get_telemetry_stats():
    return TelemetryMiddleware.get_shared_stats()

@app.get("/api/embeddings/cache/stats")
async def get_embeddings_cache_stats():
    from verba_extensions.utils.embeddings_cache import get_cache_stats
    return get_cache_stats()

@app.get("/api/etl/telemetry")
async def get_etl_telemetry():
    from verba_extensions.utils.telemetry import get_telemetry
    return get_telemetry().generate_report()
```

### `goldenverba/components/embedding/OpenAIEmbedder.py`:

```python
from verba_extensions.utils.embeddings_cache import get_cached_embedding, get_cache_key
from verba_extensions.utils.preprocess import prepare_for_embedding

def embed(self, documents, client, logging):
    for doc in documents:
        for chunk in doc.chunks:
            # Normaliza texto
            text_for_embedding = prepare_for_embedding(chunk.text)
            
            # Cache key
            cache_key = get_cache_key(
                text=text_for_embedding,
                doc_uuid=str(doc.uuid),
                parent_type="chunk"
            )
            
            # Embed com cache
            embedding, was_cached = get_cached_embedding(
                text=text_for_embedding,
                cache_key=cache_key,
                embed_fn=lambda t: self._call_openai_api(t)
            )
            
            # ... resto do c√≥digo ...
```

---

## ‚úÖ Checklist de Integra√ß√£o

- [ ] TelemetryMiddleware adicionado em `api.py`
- [ ] Endpoints de telemetria criados
- [ ] Embeddings Cache integrado em embedders
- [ ] Text Preprocessing usado antes de embedding
- [ ] Quality Scoring usado em filtros (opcional)
- [ ] Telemetry Collector usado em plugins ETL (opcional)
- [ ] UUID Determin√≠stico usado em imports (opcional)
- [ ] Testes realizados em ambiente de desenvolvimento

---

## üîç Verifica√ß√£o

Ap√≥s integrar, verifique:

1. **TelemetryMiddleware**: Logs devem aparecer com `[TELEMETRY]`
2. **Embeddings Cache**: Stats devem mostrar `hit_rate > 0` em re-uploads
3. **Quality Scoring**: Chunks de baixa qualidade devem ser filtrados
4. **Text Preprocessing**: Textos devem estar normalizados

---

## üìù Notas

- Todos os componentes s√£o **opcionais** e podem ser integrados gradualmente
- **TelemetryMiddleware** e **Embeddings Cache** s√£o os mais cr√≠ticos
- Componentes s√£o **independentes** - voc√™ pode usar apenas alguns
- **Sem depend√™ncias externas** - apenas bibliotecas padr√£o Python

---

**Pr√≥ximos Passos**: 
1. Integrar TelemetryMiddleware (mais cr√≠tico)
2. Integrar Embeddings Cache (maior impacto em performance)
3. Adicionar outros componentes conforme necessidade

