# üìñ Explica√ß√£o Completa: O Que Acontece com um PDF de Artigos sobre Empresas?

## üéØ Cen√°rio

Voc√™ faz upload de um PDF chamado `artigos_empresas.pdf` que cont√©m:
- **Artigo 1**: "Apple lan√ßa novo iPhone"
- **Artigo 2**: "Microsoft anuncia parceria com OpenAI"
- **Artigo 3**: "Google desenvolve IA avan√ßada"

Voc√™ escolhe: **"Universal A2 (ETL Autom√°tico)"**

---

## üîÑ Fluxo Passo a Passo

### **FASE 1: Upload e Leitura** ‚è±Ô∏è ~2-5s

```
PDF ‚Üí Universal A2 Reader ‚Üí Default Reader ‚Üí Extra√ß√£o de Texto
```

**O que acontece:**
1. Voc√™ faz upload do `artigos_empresas.pdf`
2. `UniversalA2Reader` delega para `BasicReader` (Default)
3. `BasicReader` usa `pypdf` para extrair texto de todas as p√°ginas
4. Texto extra√≠do: `"[Artigo 1 completo]...\n\n[Artigo 2 completo]...\n\n[Artigo 3 completo]..."`

**Resultado:**
- ‚úÖ Um **Document** criado com:
  - `title`: "artigos_empresas.pdf"
  - `content`: Todo o texto extra√≠do (3 artigos juntos)
  - `meta.enable_etl = True` ‚Üê Marca para ETL posterior

---

### **FASE 2: ETL Pr√©-Chunking** ‚è±Ô∏è ~5-6s (OTIMIZADO)

```
Documento Completo ‚Üí Extra√ß√£o de Entidades ‚Üí Entity-Spans
```

**O que acontece:**
1. **Extra√ß√£o de Entidades** via spaCy NER:
   - Extrai apenas **ORG** (organiza√ß√µes) e **PERSON/PER** (pessoas)
   - Exclui LOC/GPE/MISC para performance (reduz 367 ‚Üí ~110 entidades)
   - **Deduplica** entidades duplicadas por posi√ß√£o
   - **Normaliza** PER (PT) ‚Üí PERSON (EN) para compatibilidade
   
2. **Armazenamento** em `document.meta["entity_spans"]`:
   ```python
   entity_spans = [
       {"text": "Apple", "start": 0, "end": 5, "label": "ORG"},
       {"text": "Fernando Carneiro", "start": 150, "end": 167, "label": "PERSON"},
       ...
   ]
   ```

**Otimiza√ß√µes:**
- ‚úÖ **Binary search** para filtragem O(n log n) em vez de O(n¬≤)
- ‚úÖ **Deduplica√ß√£o** evita processar entidades repetidas
- ‚úÖ **Filtro de tipos** reduz volume em 71%

**Resultado:**
- ‚úÖ ~110 entidades extra√≠das (ORG + PERSON apenas)
- ‚úÖ Armazenadas em `document.meta["entity_spans"]`
- ‚úÖ Prontas para uso no chunking entity-aware

---

### **FASE 3: Chunking Entity-Aware** ‚è±Ô∏è ~2-3s (OTIMIZADO)

```
Documento + Entity-Spans ‚Üí Section-Aware Chunker ‚Üí M√∫ltiplos Chunks
```

**O que acontece:**
1. **Section-Aware Chunker** usa `entity_spans` para:
   - **Evitar cortar entidades** no meio dos chunks
   - **Respeitar se√ß√µes** do documento
   - **Binary search** para filtrar entidades por se√ß√£o (O(log n))

2. Divide o texto em chunks respeitando:
   - Limites de se√ß√µes
   - Posi√ß√µes das entidades (n√£o corta no meio)

**Exemplo de chunks criados:**
```
Chunk 1: "Apple lan√ßa novo iPhone. A empresa americana anunciou..."
Chunk 2: "...caracter√≠sticas t√©cnicas incluem processador A17..."
Chunk 3: "Microsoft anuncia parceria estrat√©gica com OpenAI..."
Chunk 4: "...visa acelerar desenvolvimento de IA generativa..."
Chunk 5: "Google desenvolve novo modelo de IA avan√ßada..."
Chunk 6: "...chamado Gemini Pro, supera ChatGPT em v√°rios benchmarks..."
```

**Resultado:**
- ‚úÖ **6-10 chunks** criados (dependendo do tamanho do PDF)
- Cada chunk tem:
  - `text`: Texto do chunk
  - `doc_uuid`: ID do documento pai (ser√° atribu√≠do depois)

---

### **FASE 4: Embedding (Vectoriza√ß√£o)** ‚è±Ô∏è ~5-15s

```
Chunks ‚Üí Embedder ‚Üí Vetores (384/768/1536 dimens√µes)
```

**O que acontece:**
1. Verba usa o **embedder** escolhido (ex: SentenceTransformers)
2. Cada chunk √© convertido em um vetor num√©rico

**Exemplo:**
```
Chunk 1 ‚Üí [0.123, -0.456, 0.789, ..., 0.234] (384 n√∫meros)
Chunk 2 ‚Üí [0.234, -0.567, 0.890, ..., 0.345]
...
```

**Resultado:**
- ‚úÖ Cada chunk tem um **vetor de embedding**
- Vetores ser√£o usados para busca sem√¢ntica depois

---

### **FASE 5: Import no Weaviate** ‚è±Ô∏è ~2-5s

```
Chunks + Vetores ‚Üí Weaviate ‚Üí Armazenamento
```

**O que acontece:**
1. `WeaviateManager.import_document()` √© chamado
2. Documento √© inserido na collection `VERBA_Document`
3. Cada chunk √© inserido na collection do embedder (ex: `VERBA_Embedding_SentenceTransformers`)

**Estrutura no Weaviate:**
```
VERBA_Document:
  - uuid: "abc-123-def"
  - properties:
    - title: "artigos_empresas.pdf"
    - content: "[texto completo]"
    - source: "artigos_empresas.pdf"

VERBA_Embedding_SentenceTransformers:
  - uuid: "chunk-1"
  - properties:
    - text: "Apple lan√ßa novo iPhone..."
    - doc_uuid: "abc-123-def"
    - chunk_index: 0
  - vector: [0.123, -0.456, ...]
  
  - uuid: "chunk-2"
  - properties:
    - text: "...caracter√≠sticas t√©cnicas..."
    - doc_uuid: "abc-123-def"
    - chunk_index: 1
  - vector: [0.234, -0.567, ...]
  
  ... (mais chunks)
```

**Resultado:**
- ‚úÖ Documento e chunks armazenados no Weaviate
- ‚úÖ Chunks t√™m `doc_uuid` vinculado ao documento

---

### **FASE 6: Hook Detecta Import** ‚è±Ô∏è ~0.1s

```
import_document completo ‚Üí Hook detecta ‚Üí Prepara para ETL
```

**O que acontece:**
1. `patched_import_document()` verifica `document.meta.enable_etl`
2. Como est√° `True`, busca todos os `passage_uuids` do documento:
   ```python
   passages = await embedder_collection.query.fetch_objects(
       filters=Filter.by_property("doc_uuid").equal("abc-123-def"),
       limit=10000
   )
   passage_uuids = ["chunk-1", "chunk-2", "chunk-3", ...]
   ```
3. Dispara hook `'import.after'` em background (n√£o bloqueia)

**Resultado:**
- ‚úÖ Hook registrado para executar ETL
- ‚úÖ Lista de `passage_uuids` preparada

---

### **FASE 7: ETL P√≥s-Chunking Executa por Chunk** ‚è±Ô∏è ~10-30s (background) ‚≠ê ATUALIZADO

```
Cada Chunk ‚Üí ETL A2 Inteligente ‚Üí Entidades + Se√ß√µes ‚Üí Atualiza Weaviate
```

**‚≠ê NOVO: ETL Inteligente Multi-idioma**

**O que acontece para CADA chunk:**

#### **7.1. Detec√ß√£o de Idioma e Extra√ß√£o de Entidades** ‚≠ê NOVO

Para o **Chunk 1**: `"Apple lan√ßa novo iPhone. A empresa americana anunciou..."`

**‚≠ê NOVO: Detec√ß√£o Autom√°tica de Idioma**

```python
# 1. Detecta idioma automaticamente
from langdetect import detect
language = detect("Apple lan√ßa novo iPhone...")  # Retorna "pt"

# 2. Carrega modelo spaCy apropriado
if language == "pt":
    nlp = spacy.load("pt_core_news_sm")
elif language == "en":
    nlp = spacy.load("en_core_web_sm")
else:
    nlp = spacy.load("pt_core_news_sm")  # Fallback

# 3. Extrai entidades (modo inteligente - sem gazetteer obrigat√≥rio)
doc = nlp("Apple lan√ßa novo iPhone. A empresa americana anunciou...")

# Entidades encontradas (todas as labels):
entity_mentions = [
    {"text": "Apple", "label": "ORG", "confidence": 0.95},
    {"text": "iPhone", "label": "MISC", "confidence": 0.80},
    # Modo inteligente extrai TODAS as entidades, n√£o apenas ORG+PERSON
]
```

**‚≠ê NOVO: Modo Inteligente vs Modo Gazetteer**

**Modo Inteligente (padr√£o):**
- ‚úÖ Extrai entidades diretamente do texto
- ‚úÖ N√£o requer gazetteer manual
- ‚úÖ Funciona out-of-the-box
- ‚úÖ Salva em `entity_mentions` como JSON

**Modo Gazetteer (opcional):**
- Usa gazetteer se dispon√≠vel para normaliza√ß√£o
- Mapeia aliases para `entity_ids` can√¥nicos
- Salva em `entities_local_ids`

**Resultado:**
- ‚úÖ Lista de entidades por chunk (`entity_mentions`)
- ‚úÖ Entidades normalizadas se gazetteer dispon√≠vel (`entities_local_ids`)

---

#### **7.2. Normaliza√ß√£o via Gazetteer (Opcional)**

Para o **Chunk 1** com entidade `"Apple"`:

```python
# Gazetteer mapeia aliases para entity_ids (se dispon√≠vel)
gazetteer = {
    "Q312": ["Apple", "Apple Inc", "Apple Computer"],
    "Q2283": ["Microsoft", "MSFT", "Microsoft Corporation"],
    "Q95": ["Google", "Google LLC", "Alphabet"]
}

# Busca "Apple" no gazetteer (se dispon√≠vel)
if gazetteer:
    entity_ids = ["Q312"]  # Apple Inc (normalizado)
else:
    entity_ids = []  # Modo inteligente n√£o requer normaliza√ß√£o
```

**Resultado:**
- ‚úÖ Entidades normalizadas para `entity_ids` can√¥nicos (se gazetteer dispon√≠vel)
- ‚úÖ Modo inteligente funciona mesmo sem gazetteer

---

#### **7.3. Detec√ß√£o de Se√ß√µes**

Para o **Chunk 1** no contexto do documento completo:

```python
# Detecta se est√° em uma se√ß√£o espec√≠fica
# Procura por padr√µes: "## T√≠tulo", "Introdu√ß√£o", etc.

section_title = "Artigo 1: Apple lan√ßa novo iPhone"
section_first_para = "A empresa americana anunciou..."
section_entity_ids = ["Q312"]  # Entidades mencionadas nesta se√ß√£o
```

**Resultado:**
- ‚úÖ T√≠tulo de se√ß√£o identificado
- ‚úÖ Primeiro par√°grafo da se√ß√£o
- ‚úÖ Entidades da se√ß√£o

---

#### **7.4. Atualiza√ß√£o no Weaviate** ‚≠ê ATUALIZADO

Para **cada chunk**, atualiza metadados na **collection correta**:

```python
# ‚≠ê NOVO: Collection correta (n√£o mais "Passage")
collection_name = "VERBA_Embedding_all_MiniLM_L6_v2"  # Ou qualquer outro embedder
coll = client.collections.get(collection_name)

# Chunk 1
await coll.data.update(
    uuid="chunk-1",
    properties={
        # ‚≠ê NOVO: entity_mentions (modo inteligente)
        "entity_mentions": json.dumps([
            {"text": "Apple", "label": "ORG", "confidence": 0.95}
        ]),
        # Modo legado (se gazetteer dispon√≠vel):
        "entities_local_ids": ["Q312"],           # Entidades normalizadas
        "section_title": "Artigo 1: Apple...",
        "section_first_para": "A empresa...",
        "section_entity_ids": ["Q312"],          # Entidades da se√ß√£o
        "section_scope_confidence": 0.85,
        "etl_version": "entity_scope_intelligent_v2"  # ‚≠ê NOVO
    }
)

# Chunk 3 (sobre Microsoft)
await coll.data.update(
    uuid="chunk-3",
    properties={
        # ‚≠ê NOVO: entity_mentions (modo inteligente)
        "entity_mentions": json.dumps([
            {"text": "Microsoft", "label": "ORG", "confidence": 0.95},
            {"text": "OpenAI", "label": "ORG", "confidence": 0.90}
        ]),
        # Modo legado (se gazetteer dispon√≠vel):
        "entities_local_ids": ["Q2283"],          # Microsoft
        "section_title": "Artigo 2: Microsoft...",
        "section_first_para": "Microsoft anuncia...",
        "section_entity_ids": ["Q2283", "Q199300"],  # Microsoft + OpenAI
        "etl_version": "entity_scope_intelligent_v2"  # ‚≠ê NOVO
    }
)
```

**Resultado:**
- ‚úÖ Cada chunk tem metadados de entidades
- ‚úÖ Metadados de se√ß√£o preenchidos

---

### **FASE 8: Consolida√ß√£o no Article** ‚è±Ô∏è ~1-2s

```
Passages atualizados ‚Üí Consolida entidades ‚Üí Atualiza Article
```

**O que acontece:**
1. ETL coleta todas as `entities_local_ids` de todos os chunks
2. Cria/atualiza collection `Article` (se usar schema A2)
3. Atualiza `entities_all_ids` com todas as entidades √∫nicas

```python
# Article consolidado
article_collection.data.insert(
    properties={
        "article_id": "abc-123-def",
        "url_final": "doc://artigos_empresas.pdf",
        "title": "artigos_empresas.pdf",
        "entities_all_ids": ["Q312", "Q2283", "Q199300", "Q95"],  # Todas as empresas
        "source_domain": "local",
        "published_at": "2025-01-15"
    }
)
```

**Resultado:**
- ‚úÖ `Article` criado com todas as entidades consolidadas
- ‚úÖ Relacionamento Article ‚Üî Passages estabelecido

---

## üìä Resultado Final no Weaviate

### **Documento Original:**
```
VERBA_Document:
  - title: "artigos_empresas.pdf"
  - content: "[texto completo dos 3 artigos]"
```

### **Chunks (Passages) com ETL:** ‚≠ê ATUALIZADO
```
Chunk 1 (Apple):
  - text: "Apple lan√ßa novo iPhone..."
  - entity_mentions: [{"text": "Apple", "label": "ORG", "confidence": 0.95}]  ‚≠ê NOVO
  - entities_local_ids: ["Q312"]              ‚Üê Apple Inc (se gazetteer dispon√≠vel)
  - section_title: "Artigo 1: Apple..."
  - section_entity_ids: ["Q312"]
  - etl_version: "entity_scope_intelligent_v2"  ‚≠ê NOVO

Chunk 3 (Microsoft):
  - text: "Microsoft anuncia parceria..."
  - entity_mentions: [{"text": "Microsoft", "label": "ORG", "confidence": 0.95}, {"text": "OpenAI", "label": "ORG", "confidence": 0.90}]  ‚≠ê NOVO
  - entities_local_ids: ["Q2283"]            ‚Üê Microsoft (se gazetteer dispon√≠vel)
  - section_entity_ids: ["Q2283", "Q199300"]  ‚Üê Microsoft + OpenAI
  - etl_version: "entity_scope_intelligent_v2"  ‚≠ê NOVO

Chunk 5 (Google):
  - text: "Google desenvolve IA..."
  - entity_mentions: [{"text": "Google", "label": "ORG", "confidence": 0.95}]  ‚≠ê NOVO
  - entities_local_ids: ["Q95"]              ‚Üê Google (se gazetteer dispon√≠vel)
  - section_entity_ids: ["Q95"]
  - etl_version: "entity_scope_intelligent_v2"  ‚≠ê NOVO
```

### **Article (se usar schema A2):**
```
Article:
  - article_id: "abc-123-def"
  - title: "artigos_empresas.pdf"
  - entities_all_ids: ["Q312", "Q2283", "Q199300", "Q95"]  ‚Üê Todas as empresas
```

---

## üéØ Como Usar Depois

### **Busca por Entidade Espec√≠fica:**

Use **Entity-Aware Retriever**:
```
Query: "inova√ß√£o tecnol√≥gica"
+ Filter: entities_local_ids contains "Q312" (Apple)

Resultado:
- Retorna apenas chunks que mencionam Apple
- Evita contamina√ß√£o com Microsoft/Google
```

### **Busca por Se√ß√£o:**

```
Query: "parcerias"
+ Filter: section_entity_ids contains "Q2283" (Microsoft)

Resultado:
- Retorna apenas se√ß√£o sobre Microsoft
```

### **Busca H√≠brida:**

```
Query: "intelig√™ncia artificial"
+ Filter: entities_all_ids contains any of ["Q95", "Q2283"] (Google ou Microsoft)

Resultado:
- Chunks sobre Google ou Microsoft relacionados a IA
- Exclui Apple automaticamente
```

---

## ‚è±Ô∏è Tempo Total Estimado (OTIMIZADO)

- **Upload + Leitura**: 2-5s
- **ETL Pr√©-Chunking**: 5-6s (otimizado: 71% menos entidades)
- **Chunking Entity-Aware**: 2-3s (otimizado: binary search, 10-15x mais r√°pido)
- **Embedding**: 5-15s
  - ‚ö†Ô∏è **NOTA:** `recursive_document_splitter` foi removido (evita expans√£o 93 ‚Üí 2379 chunks)
- **Import Weaviate**: 2-5s
- **ETL P√≥s-Chunking (background)**: 10-30s
  - ‚≠ê **NOVO:** ETL inteligente multi-idioma (detec√ß√£o autom√°tica PT/EN)
  - ‚≠ê **NOVO:** Collection correta sendo usada (n√£o mais "Passage")
- **Total**: **26-64 segundos**

**Antes das otimiza√ß√µes**: 30s+ apenas no chunking  
**Depois das otimiza√ß√µes**: 2-3s no chunking  
**Ganho total**: **10-15x mais r√°pido** no chunking!

**Importante**: ETL p√≥s-chunking executa em background, ent√£o voc√™ pode continuar usando o Verba enquanto processa!

---

## üí° Pontos Importantes

### ‚úÖ **Vantagens:**
1. **Autom√°tico**: Voc√™ s√≥ faz upload e importa
2. **Por Chunk**: Entidades extra√≠das contextualmente
3. **Normalizado**: Aliases mapeados para IDs can√¥nicos
4. **Se√ß√µes**: Detec√ß√£o autom√°tica de estrutura
5. **Background**: N√£o bloqueia interface

### ‚ö†Ô∏è **Limita√ß√µes:**
1. **SpaCy**: Requer modelo instalado (`pt_core_news_sm` ou `en_core_web_sm`)
   - ‚≠ê **NOVO:** Modelo √© carregado automaticamente baseado no idioma detectado
2. **Gazetteer**: ‚≠ê **OPCIONAL** - ETL inteligente funciona sem gazetteer
   - Modo inteligente: extrai entidades diretamente (n√£o requer gazetteer)
   - Modo legado: usa gazetteer se dispon√≠vel para normaliza√ß√£o
3. **Performance**: ETL adiciona 10-30s por documento (p√≥s-chunking, em background)
4. **PDF Complexo**: Pode n√£o separar artigos automaticamente (se forem cont√≠nuos)
5. **Tipos de Entidades**: ‚≠ê **ATUALIZADO** - Modo inteligente extrai TODAS as labels
   - Modo pr√©-chunking: apenas ORG + PERSON (otimiza√ß√£o)
   - Modo p√≥s-chunking: todas as labels (ORG, PERSON, LOC, GPE, MISC, etc.)

### üöÄ **Otimiza√ß√µes Implementadas:**
1. **Binary Search**: Filtragem O(n¬≤) ‚Üí O(n log n) (6.7x mais r√°pido)
2. **Deduplica√ß√£o**: Remove entidades duplicadas por posi√ß√£o
3. **Filtro de Tipos**: Apenas ORG + PERSON (reduz 71% das entidades)
4. **Normaliza√ß√£o**: PER (PT) ‚Üí PERSON (EN) para compatibilidade
5. **Entity-Aware**: Chunking n√£o corta entidades no meio (qualidade mantida)

---

## üîß Ajustes Poss√≠veis

### **Se PDF tem m√∫ltiplos artigos bem separados:**

O Verba pode criar m√∫ltiplos documentos se houver quebras claras. Mas se tudo vem como um √∫nico documento:

**Op√ß√£o 1**: Use o script `pdf_to_a2_json.py` para separar manualmente
**Op√ß√£o 2**: Importe como est√° - ETL processa todos os chunks mesmo assim

### **Se alguma empresa n√£o √© detectada:**

**‚≠ê NOVO: Modo Inteligente (sem gazetteer):**
- ETL detecta entidades automaticamente via spaCy
- N√£o requer gazetteer manual
- Funciona out-of-the-box

**Modo Legado (com gazetteer):**
- Adicione ao `gazetteer.json` para normaliza√ß√£o:
```json
{
  "entity_id": "Q999",
  "aliases": ["Nome da Empresa", "Nome Alternativo", "Sigla"]
}
```
- Gazetteer √© opcional - ETL funciona sem ele

---

**Agora voc√™ entende exatamente o que acontece quando faz upload de um PDF com artigos sobre empresas!** üéâ

