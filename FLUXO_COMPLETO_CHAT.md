# ğŸ¬ Fluxo Completo do Chat: Query â†’ Retrieval â†’ LLM â†’ Resposta

## ğŸ“Š **VisÃ£o Geral**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USUÃRIO digita no chat: "apple e inovaÃ§Ã£o"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ RETRIEVAL    â”‚      â”‚ LLM GENERATION       â”‚
  â”‚ (Nosso foco) â”‚      â”‚ (AnthropicGenerator) â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â†‘
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Chunks + Contexto

                     â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESPOSTA GERADA: "Apple Ã© conhecida pela inovaÃ§Ã£o em..."         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ **Fluxo Detalhado: 4 Etapas**

### **ETAPA 1ï¸âƒ£: Chat Interface (Frontend)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend (React)                                            â”‚
â”‚                                                             â”‚
â”‚ [UsuÃ¡rio digita]: "apple e inovaÃ§Ã£o"                       â”‚
â”‚ [Clica em Send]                                             â”‚
â”‚                                                             â”‚
â”‚ â†’ Envia via WebSocket para backend                         â”‚
â”‚   POST /ws/generate_stream                                  â”‚
â”‚   {                                                         â”‚
â”‚     "query": "apple e inovaÃ§Ã£o",                           â”‚
â”‚     "rag_config": {...},                                    â”‚
â”‚     "context": "",                                          â”‚
â”‚     "conversation": []                                      â”‚
â”‚   }                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
```

**CÃ³digo:** `frontend/app/components/Chat/ChatInterface.tsx`
```typescript
const sendUserMessage = async () => {
  const sendInput = userInput;  // "apple e inovaÃ§Ã£o"
  
  const data = await sendUserQuery(
    sendInput,           // â† Query
    RAGConfig,           // â† Config do retriever
    filterLabels,
    documentFilter,
    credentials
  );
};
```

---

### **ETAPA 2ï¸âƒ£: Retrieval (Busca de Documentos) â­ AQUI Ã‰ O QUERY PARSING**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend - Retrieval Stage                                   â”‚
â”‚                                                             â”‚
â”‚ /api/query endpoint (goldenverba/server/api.py:504)       â”‚
â”‚                                                             â”‚
â”‚ âœ… FLUXO DE RETRIEVAL                                      â”‚
â”‚                                                             â”‚
â”‚ 1. Query chega: "apple e inovaÃ§Ã£o"                        â”‚
â”‚    â†“                                                        â”‚
â”‚ 2. EntityAwareRetriever.retrieve()                         â”‚
â”‚    â”œâ”€ Chama hook: entity_aware.get_filters                â”‚
â”‚    â”‚                                                        â”‚
â”‚    â””â”€â†’ QueryOrchestrator executa:                         â”‚
â”‚        â€¢ extract_entities_from_query()  â† spaCy NER       â”‚
â”‚          Resultado: ["Apple"] (ORG)                       â”‚
â”‚                                                             â”‚
â”‚        â€¢ parse_query() â† [NOVO - Query Parser]            â”‚
â”‚          Separa: entidades vs semÃ¢ntica                   â”‚
â”‚          Resultado: {                                     â”‚
â”‚            entities: ["Apple"],                           â”‚
â”‚            semantic_concepts: ["inovaÃ§Ã£o"]                â”‚
â”‚          }                                                 â”‚
â”‚    â†“                                                        â”‚
â”‚ 3. Weaviate Busca HÃ­brida                                 â”‚
â”‚    â”œâ”€ WHERE filter: entities = "Apple" (rÃ¡pido)          â”‚
â”‚    â””â”€ Vector search: "inovaÃ§Ã£o" (relevÃ¢ncia)             â”‚
â”‚    â†“                                                        â”‚
â”‚ 4. Retorna chunks relevantes                              â”‚
â”‚    {                                                       â”‚
â”‚      "documents": [                                        â”‚
â”‚        {                                                   â”‚
â”‚          "uuid": "doc-123",                               â”‚
â”‚          "title": "Apple Innovation Strategy",            â”‚
â”‚          "chunks": [                                       â”‚
â”‚            "Apple investe em inovaÃ§Ã£o de IA...",          â”‚
â”‚            "A estratÃ©gia de inovaÃ§Ã£o foca em..."          â”‚
â”‚          ]                                                 â”‚
â”‚        }                                                   â”‚
â”‚      ],                                                    â”‚
â”‚      "context": "Apple Innovation Strategy... [chunks]"   â”‚
â”‚    }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“ (Chunks + Context)
```

**CÃ³digo:** `goldenverba/server/api.py`
```python
@app.post("/api/query")
async def query(payload: QueryPayload):
    documents, context = await manager.retrieve_chunks(
        client, 
        payload.query,           # â† "apple e inovaÃ§Ã£o"
        payload.RAG,             # â† EntityAware Retriever config
        payload.labels, 
        documents_uuid
    )
    return {
        "documents": documents,  # â† Chunks encontrados
        "context": context       # â† Texto concatenado
    }
```

---

### **ETAPA 3ï¸âƒ£: LLM Generation (GeraÃ§Ã£o de Resposta) â­ AQUI USA O AGENTE**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend - Generation Stage                                  â”‚
â”‚                                                             â”‚
â”‚ manager.generate_stream_answer()                            â”‚
â”‚                                                             â”‚
â”‚ âœ… FLUXO DE GERAÃ‡ÃƒO                                        â”‚
â”‚                                                             â”‚
â”‚ 1. Recebe chunks do retrieval:                             â”‚
â”‚    "Apple Innovation Strategy... [chunks]"                 â”‚
â”‚    â†“                                                        â”‚
â”‚ 2. ConstrÃ³i prompt:                                        â”‚
â”‚    """                                                      â”‚
â”‚    You are a helpful assistant.                            â”‚
â”‚    Use the following context to answer.                    â”‚
â”‚                                                             â”‚
â”‚    Context:                                                â”‚
â”‚    Apple Innovation Strategy...                            â”‚
â”‚    [chunks sobre apple + inovaÃ§Ã£o]                         â”‚
â”‚                                                             â”‚
â”‚    User Question: apple e inovaÃ§Ã£o                         â”‚
â”‚    """                                                      â”‚
â”‚    â†“                                                        â”‚
â”‚ 3. Envia para LLM (AnthropicGenerator) ğŸ¤–                 â”‚
â”‚    â”œâ”€ Model: claude-3-sonnet (ou configurado)             â”‚
â”‚    â”œâ”€ Temperature: config                                  â”‚
â”‚    â”œâ”€ Max tokens: config                                  â”‚
â”‚    â””â”€ Streaming: SIM (em tempo real)                      â”‚
â”‚    â†“                                                        â”‚
â”‚ 4. LLM processa:                                           â”‚
â”‚    LÃª os chunks sobre Apple + inovaÃ§Ã£o                    â”‚
â”‚    Gera resposta coerente                                  â”‚
â”‚    Envia chunk por chunk (streaming)                       â”‚
â”‚    â†“                                                        â”‚
â”‚ 5. Resposta:                                               â”‚
â”‚    "Apple Ã© conhecida por sua constante inovaÃ§Ã£o          â”‚
â”‚     em design e tecnologia. A empresa investe..."          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“ (Streaming chunks)
```

**CÃ³digo:** `goldenverba/components/generation/AnthropicGenerator.py`
```python
class AnthropicGenerator(LLM):
    async def generate_answer(self, prompt: str, config: Dict):
        """Gera resposta usando API Anthropic"""
        
        client = Anthropic(api_key=self.api_key)
        
        # Streaming
        with client.messages.stream(
            model="claude-3-sonnet-20240229",
            max_tokens=config.get("Max Tokens", 1024),
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            for text in stream.text_stream:
                yield text  # â† Envia em tempo real
```

**Exemplo de Prompt ConstruÃ­do:**
```
System: You are a helpful AI assistant specialized in answering questions based on provided context.

Context (from retrieved documents):
---
Apple Inc. has a strategic focus on innovation across its product lines. 
The company invests heavily in R&D for new technologies including AI, 
machine learning, and sustainable materials...

[Mais 10-20 chunks similares]
---

User: apple e inovaÃ§Ã£o

```

---

### **ETAPA 4ï¸âƒ£: Frontend Recebe Resposta (Streaming)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WebSocket /ws/generate_stream                               â”‚
â”‚                                                             â”‚
â”‚ âœ… FLUXO DE RECEPÃ‡ÃƒO (STREAMING)                           â”‚
â”‚                                                             â”‚
â”‚ 1. Frontend conectado no WebSocket                          â”‚
â”‚    Aguardando chunks da resposta                            â”‚
â”‚    â†“                                                        â”‚
â”‚ 2. Backend envia chunks em tempo real:                      â”‚
â”‚    {                                                        â”‚
â”‚      "message": "Apple",                                    â”‚
â”‚      "finish_reason": null                                  â”‚
â”‚    }                                                        â”‚
â”‚    {                                                        â”‚
â”‚      "message": " Ã© conhecida",                             â”‚
â”‚      "finish_reason": null                                  â”‚
â”‚    }                                                        â”‚
â”‚    {                                                        â”‚
â”‚      "message": " pela inovaÃ§Ã£o...",                        â”‚
â”‚      "finish_reason": null                                  â”‚
â”‚    }                                                        â”‚
â”‚    {                                                        â”‚
â”‚      "message": "",                                         â”‚
â”‚      "finish_reason": "stop"                                â”‚
â”‚    }                                                        â”‚
â”‚    â†“                                                        â”‚
â”‚ 3. Frontend renderiza em tempo real                         â”‚
â”‚    UsuÃ¡rio vÃª a resposta aparecer palavra por palavra       â”‚
â”‚    â†“                                                        â”‚
â”‚ 4. Resposta Final:                                          â”‚
â”‚    "Apple Ã© conhecida pela inovaÃ§Ã£o em design, tecnologia   â”‚
â”‚     e sustentabilidade. A empresa investe bilhÃµes em        â”‚
â”‚     pesquisa e desenvolvimento para trazer produtos         â”‚
â”‚     inovadores ao mercado."                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo:** `goldenverba/server/api.py`
```python
@app.websocket("/ws/generate_stream")
async def websocket_generate_stream(websocket: WebSocket):
    await websocket.accept()
    while True:
        data = await websocket.receive_text()
        payload = GeneratePayload.model_validate_json(data)
        
        full_text = ""
        async for chunk in manager.generate_stream_answer(
            payload.rag_config,
            payload.query,           # â† "apple e inovaÃ§Ã£o"
            payload.context,         # â† Chunks do retrieval
            payload.conversation,
        ):
            full_text += chunk["message"]
            if chunk["finish_reason"] == "stop":
                chunk["full_text"] = full_text
            await websocket.send_json(chunk)  # â† Envia em tempo real
```

---

## ğŸ§  **Resumo: Quem Faz o QuÃª**

| Componente | FunÃ§Ã£o | Tecnologia | Exemplo |
|---|---|---|---|
| **QueryParser** | Separa entidades de conceitos | spaCy NER + POS | "apple" (entidade) + "inovaÃ§Ã£o" (conceito) |
| **EntityAwareRetriever** | Busca chunks relevantes | Weaviate WHERE + Vector | Retorna chunks sobre Apple + inovaÃ§Ã£o |
| **AnthropicGenerator** | Gera resposta usando LLM | Claude 3 API | "Apple Ã© conhecida pela inovaÃ§Ã£o..." |
| **Frontend** | Exibe resposta | React + WebSocket | Mostra em tempo real (streaming) |

---

## ğŸ¯ **Onde Entra o Query Parser**

```
UsuÃ¡rio: "apple e inovaÃ§Ã£o"
      â†“
[QueryParser]  â† NOVO!
      â”œâ”€ Extrai: entidade="Apple", conceito="inovaÃ§Ã£o"
      â””â”€ Classifica: intent="COMBINATION"
      â†“
[EntityAwareRetriever]
      â”œâ”€ Aplica filtro WHERE: entities = "Apple"
      â””â”€ Busca vetorial: "inovaÃ§Ã£o"
      â†“
[Weaviate]
      â†’ Retorna chunks sobre (Apple AND inovaÃ§Ã£o)
      â†“
[AnthropicGenerator]
      â†’ LÃª chunks, gera resposta
      â†“
[Frontend]
      â†’ Exibe streaming da resposta
```

---

## ğŸ“‹ **ComparaÃ§Ã£o: Com vs Sem Query Parser**

### **SEM Query Parser (Hoje - Limitado)**

```
Query: "apple e inovaÃ§Ã£o"
     â†“
extract_entities_from_query()
     â†’ Encontra: ["Apple"]
     â†’ Ignora: "inovaÃ§Ã£o"
     â†“
Weaviate: WHERE entities = "Apple"
     â†’ Retorna: Chunks sobre Apple (em qualquer contexto)
     â†’ PROBLEMA: Pode incluir chunks que nÃ£o falam de inovaÃ§Ã£o
     â†“
LLM recebe contexto incorreto
     â†’ Resposta pode nÃ£o abordar "inovaÃ§Ã£o" adequadamente
```

### **COM Query Parser (Novo - Completo)**

```
Query: "apple e inovaÃ§Ã£o"
     â†“
parse_query()
     â†’ Entidades: ["Apple"]
     â†’ Conceitos: ["inovaÃ§Ã£o"]
     â†’ Intent: "COMBINATION"
     â†“
Weaviate: WHERE entities = "Apple" AND vector_search("inovaÃ§Ã£o")
     â†’ Retorna: Chunks sobre Apple que mencionam inovaÃ§Ã£o
     â†’ âœ… CORRETO: Contextualmente relevante
     â†“
LLM recebe contexto perfeito
     â†’ Resposta aborda Apple + inovaÃ§Ã£o de forma coerente
```

---

## ğŸ”— **Arquitetura Visual Completa**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   UsuÃ¡rio    â”‚
                    â”‚   (Chat)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Frontend        â”‚
                    â”‚  (React)         â”‚
                    â”‚  ChatInterface   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ Query: "apple e inovaÃ§Ã£o"
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚ /api/query (Retrieval Stage)        â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â”‚  1. QueryParser                     â”‚    â”‚
    â”‚     â”œâ”€ entities: ["Apple"]          â”‚    â”‚
    â”‚     â””â”€ concepts: ["inovaÃ§Ã£o"]       â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â”‚  2. EntityAwareRetriever            â”‚    â”‚
    â”‚     â”œâ”€ WHERE filter: entities       â”‚    â”‚
    â”‚     â””â”€ Vector: concepts             â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â”‚  3. Weaviate                        â”‚    â”‚
    â”‚     â†’ Chunks relevantes             â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚ {documents, context}                 â”‚
        â”‚                                       â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚ /ws/generate_stream (Generation)    â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â”‚  1. AnthropicGenerator              â”‚    â”‚
    â”‚     â€¢ Model: Claude 3               â”‚    â”‚
    â”‚     â€¢ Prompt: context + query       â”‚    â”‚
    â”‚     â€¢ Streaming: SIM                â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â”‚  2. LLM API (Anthropic)             â”‚    â”‚
    â”‚     â†’ Resposta gerada               â”‚    â”‚
    â”‚                                     â”‚    â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚ {message, finish_reason}             â”‚
        â”‚                                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Frontend        â”‚
            â”‚  (Streaming)     â”‚
            â”‚  Mostra resposta  â”‚
            â”‚  em tempo real    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   UsuÃ¡rio vÃª:    â”‚
            â”‚  "Apple Ã©        â”‚
            â”‚   conhecida      â”‚
            â”‚   pela inovaÃ§Ã£o  â”‚
            â”‚   em..."         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ **Resposta Direta: Sim, Usa LLM!**

**A sequÃªncia Ã©:**

1. **QueryParser** â†’ Entende o que procurar (entidade vs conceito)
2. **Retriever** â†’ Busca chunks relevantes
3. **LLM (Claude)** â†’ **Gera a resposta usando esses chunks**
4. **Frontend** â†’ Exibe em streaming

O Query Parser Ã© apenas o **primeiro passo** para melhorar a qualidade dos chunks que o LLM vai receber. Sem o Query Parser, o LLM recebe chunks de mÃ¡ qualidade. Com ele, recebe chunks perfeitamente alinhados com a intenÃ§Ã£o do usuÃ¡rio.
