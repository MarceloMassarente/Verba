# üéØ Query Parsing: Como Separar Entidade vs Sem√¢ntica

## ‚ùì **O Problema**

```
Query: "apple e inova√ß√£o"
          ^^^^^   ^^^^^^^^^^
       Entidade   Sem√¢ntica?

O sistema precisa saber:
- "apple" ‚Üí procurar como ENTIDADE (filtro WHERE)
- "inova√ß√£o" ‚Üí procurar como SEM√ÇNTICA (busca vetorial)
```

---

## üß© **Estrat√©gia 1: An√°lise POS (Part-of-Speech) + NER**

### **Como Funciona**

```python
import spacy

nlp = spacy.load("pt_core_news_sm")
query = "apple e inova√ß√£o"

doc = nlp(query)

for token in doc:
    print(f"{token.text:15} | POS: {token.pos_:6} | ENT: {token.ent_type_}")

# OUTPUT:
# apple           | POS: PROPN  | ENT: ORG
# e               | POS: CCONJ  | ENT: 
# inova√ß√£o        | POS: NOUN   | ENT: 

# INTERPRETA√á√ÉO:
# - PROPN (Proper Noun) + ORG ‚Üí ENTIDADE
# - NOUN (Common Noun) sem NER ‚Üí SEM√ÇNTICA
```

### **L√≥gica**

```python
def classify_token(token):
    """Classifica se token √© entidade ou sem√¢ntico"""
    
    # 1. Se tem NER label e √© PROPN ‚Üí ENTIDADE
    if token.ent_type_ in ["ORG", "PERSON", "GPE", "LOC"]:
        return "ENTITY"
    
    # 2. Se √© nome pr√≥prio ‚Üí ENTIDADE (mesmo sem NER)
    if token.pos_ == "PROPN":
        return "ENTITY"
    
    # 3. Se √© substantivo comum ‚Üí SEM√ÇNTICO
    if token.pos_ in ["NOUN", "VERB", "ADJ"]:
        return "SEMANTIC"
    
    # 4. Palavras de conex√£o ‚Üí IGNORAR
    if token.pos_ in ["CCONJ", "ADP", "DET"]:
        return "CONNECTOR"
    
    return "OTHER"

# Teste
for token in doc:
    classification = classify_token(token)
    print(f"{token.text:15} ‚Üí {classification}")

# OUTPUT:
# apple           ‚Üí ENTITY
# e               ‚Üí CONNECTOR
# inova√ß√£o        ‚Üí SEMANTIC
```

---

## üîç **Estrat√©gia 2: Dependency Parsing (An√°lise de Depend√™ncias)**

### **Como Funciona**

```python
query = "qual √© a estrat√©gia de inova√ß√£o da Apple?"

doc = nlp(query)

for token in doc:
    if token.dep_ != "punct":  # Ignora pontua√ß√£o
        print(f"{token.text:15} ‚Üí {token.dep_:10} (parent: {token.head.text})")

# OUTPUT:
# qual            ‚Üí ROOT       (parent: √©)
# √©               ‚Üí ROOT       (parent: √©)
# a               ‚Üí det        (parent: estrat√©gia)
# estrat√©gia      ‚Üí attr       (parent: √©)
# de              ‚Üí case       (parent: inova√ß√£o)
# inova√ß√£o        ‚Üí nmod       (parent: estrat√©gia)  ‚Üê SEM√ÇNTICA!
# da              ‚Üí case       (parent: Apple)
# Apple           ‚Üí nmod       (parent: inova√ß√£o)   ‚Üê ENTIDADE!

# INTERPRETA√á√ÉO DA ESTRUTURA:
# [estrat√©gia] ‚Üê tem NMODifier
#   ‚îú‚îÄ [inova√ß√£o] (conceito)
#   ‚îî‚îÄ [de Apple] (entidade)
```

### **L√≥gica**

```python
def extract_semantic_and_entities(query):
    """Extrai componentes sem√¢nticos e entidades da query"""
    
    doc = nlp(query)
    entities = []
    semantic_concepts = []
    
    for token in doc:
        # Entidades nomeadas
        if token.ent_type_ in ["ORG", "PERSON", "GPE"]:
            entities.append(token.text)
        
        # Conceitos: NOUN ou ADJ (que n√£o sejam entidades)
        elif token.pos_ in ["NOUN", "ADJ"] and token.ent_type_ == "":
            semantic_concepts.append(token.text)
    
    return entities, semantic_concepts

# Teste
entities, concepts = extract_semantic_and_entities(
    "qual √© a estrat√©gia de inova√ß√£o da Apple?"
)

print(f"Entidades: {entities}")          # ['Apple']
print(f"Conceitos: {concepts}")          # ['estrat√©gia', 'inova√ß√£o']
```

---

## üß† **Estrat√©gia 3: Query Intent Classification**

### **Como Funciona**

```python
def classify_query_intent(query):
    """Classifica a INTEN√á√ÉO da query"""
    
    # Pattern matching
    if any(word in query.lower() for word in ["qual", "o que", "como"]):
        return "QUESTION"
    
    if any(word in query.lower() for word in ["compara√ß√£o", "vs", "versus"]):
        return "COMPARISON"
    
    if any(word in query.lower() for word in ["e", "ambos", "combina√ß√£o"]):
        return "COMBINATION"
    
    return "GENERAL_SEARCH"

# Teste
queries = [
    "qual √© a estrat√©gia de Apple?",
    "Apple vs Microsoft",
    "Apple e inova√ß√£o",
    "empresas de tecnologia"
]

for q in queries:
    intent = classify_query_intent(q)
    print(f"{q:40} ‚Üí {intent}")

# OUTPUT:
# qual √© a estrat√©gia de Apple?        ‚Üí QUESTION
# Apple vs Microsoft                   ‚Üí COMPARISON
# Apple e inova√ß√£o                     ‚Üí COMBINATION
# empresas de tecnologia               ‚Üí GENERAL_SEARCH
```

---

## ‚öôÔ∏è **Estrat√©gia 4: Fuzzy Matching com Gazetteer**

### **Como Funciona**

```python
from fuzzywuzzy import fuzz

GAZETTEER = {
    "Q123": ["Apple", "Apple Inc.", "AAPL"],
    "Q456": ["Microsoft", "MSFT"],
    "Q789": ["Steve Jobs", "Jobs"],
}

def find_entities_in_query(query):
    """Encontra entidades usando fuzzy matching"""
    
    entities_found = []
    words = query.split()
    
    # Tenta bigrams tamb√©m
    for i in range(len(words) - 1):
        bigram = f"{words[i]} {words[i+1]}"
        for entity_id, aliases in GAZETTEER.items():
            for alias in aliases:
                # Fuzzy match (n√£o precisa ser 100% exato)
                similarity = fuzz.ratio(bigram.lower(), alias.lower())
                if similarity > 80:  # 80% de similaridade
                    entities_found.append({
                        "entity_id": entity_id,
                        "alias": alias,
                        "similarity": similarity
                    })
    
    return entities_found

# Teste
query = "apple e inova√ß√£o"
entities = find_entities_in_query(query)

for e in entities:
    print(f"Entity: {e['alias']} ({e['entity_id']}) - {e['similarity']}% match")

# OUTPUT:
# Entity: Apple (Q123) - 100% match
```

---

## üéØ **Estrat√©gia 5: RECOMENDADA - Combina√ß√£o H√≠brida**

### **Pseudoc√≥digo Completo**

```python
class QueryParser:
    def __init__(self, nlp_model, gazetteer):
        self.nlp = nlp_model
        self.gazetteer = gazetteer
    
    def parse(self, query):
        """Faz parsing completo da query"""
        
        doc = self.nlp(query)
        result = {
            "entities": [],
            "semantic_concepts": [],
            "intent": self._classify_intent(query),
            "tokens": []
        }
        
        # 1. NER + POS tagging
        for token in doc:
            token_info = {
                "text": token.text,
                "pos": token.pos_,
                "ent_type": token.ent_type_,
                "dep": token.dep_
            }
            
            # 2. Classifica cada token
            if token.ent_type_ in ["ORG", "PERSON", "GPE"]:
                # √â entidade nomeada
                entity_id = self._lookup_gazetteer(token.text)
                result["entities"].append({
                    "text": token.text,
                    "entity_id": entity_id,
                    "confidence": 0.95,
                    "source": "NER"
                })
                token_info["classification"] = "ENTITY"
            
            elif token.pos_ in ["NOUN", "ADJ"] and token.ent_type_ == "":
                # √â conceito sem√¢ntico
                result["semantic_concepts"].append(token.text)
                token_info["classification"] = "SEMANTIC"
            
            elif token.pos_ in ["CCONJ", "ADP"]:
                token_info["classification"] = "CONNECTOR"
            
            result["tokens"].append(token_info)
        
        return result
    
    def _lookup_gazetteer(self, text):
        """Procura text no gazetteer"""
        for entity_id, aliases in self.gazetteer.items():
            if text.lower() in [a.lower() for a in aliases]:
                return entity_id
        return None
    
    def _classify_intent(self, query):
        """Classifica inten√ß√£o da query"""
        if "vs" in query.lower() or "versus" in query.lower():
            return "COMPARISON"
        if "e" in query.lower() or "ambos" in query.lower():
            return "COMBINATION"
        if any(w in query.lower() for w in ["qual", "o que", "como"]):
            return "QUESTION"
        return "GENERAL_SEARCH"

# Uso
parser = QueryParser(nlp, GAZETTEER)
result = parser.parse("Apple e inova√ß√£o em design")

print(result)
# OUTPUT:
# {
#   "entities": [
#     {"text": "Apple", "entity_id": "Q123", "confidence": 0.95, "source": "NER"}
#   ],
#   "semantic_concepts": ["inova√ß√£o", "design"],
#   "intent": "COMBINATION",
#   "tokens": [...]
# }
```

---

## üìä **Matriz de Decis√£o: Quando Usar Cada Estrat√©gia**

| Query | Strategy | Entities | Semantic | Intent |
|-------|----------|----------|----------|--------|
| `"Apple"` | NER | ["Apple"] | [] | GENERAL |
| `"inova√ß√£o"` | POS | [] | ["inova√ß√£o"] | GENERAL |
| `"Apple e inova√ß√£o"` | Hybrid | ["Apple"] | ["inova√ß√£o"] | COMBINATION |
| `"Apple vs Microsoft"` | Intent | ["Apple", "Microsoft"] | [] | COMPARISON |
| `"qual √© a inova√ß√£o da Apple?"` | Dependency | ["Apple"] | ["inova√ß√£o"] | QUESTION |
| `"empresas de tech"` | POS | [] | ["empresas", "tech"] | GENERAL |

---

## üöÄ **Implementa√ß√£o Pr√°tica para Verba**

### **1. Adicionar ao QueryOrchestrator**

```python
# verba_extensions/plugins/entity_aware_query_orchestrator.py

def parse_query_for_hybrid_search(query: str) -> Dict[str, Any]:
    """Parse query para extrair entidades e conceitos"""
    
    nlp = get_nlp()
    doc = nlp(query)
    
    result = {
        "original_query": query,
        "entities": [],
        "semantic_terms": [],
        "intent": "GENERAL"
    }
    
    # 1. Extrai entidades
    for ent in doc.ents:
        if ent.label_ in ["ORG", "PERSON", "GPE"]:
            entity_id = gazetteer_lookup(ent.text)
            result["entities"].append({
                "text": ent.text,
                "entity_id": entity_id
            })
    
    # 2. Extrai conceitos sem√¢nticos
    for token in doc:
        if token.pos_ in ["NOUN", "ADJ"] and token.ent_type_ == "":
            result["semantic_terms"].append(token.text)
    
    # 3. Classifica intent
    if "vs" in query.lower():
        result["intent"] = "COMPARISON"
    elif " e " in query.lower():
        result["intent"] = "COMBINATION"
    
    return result

# Uso
query_parse = parse_query_for_hybrid_search("Apple e inova√ß√£o")
# ‚Üí {
#     "entities": [{"text": "Apple", "entity_id": "Q123"}],
#     "semantic_terms": ["inova√ß√£o"],
#     "intent": "COMBINATION"
#   }
```

### **2. Usar no Retriever**

```python
# entity_aware_retriever.py

async def retrieve(self, query, config, ...):
    # 1. Parse query
    parsed = parse_query_for_hybrid_search(query)
    
    # 2. Se tem entidades ‚Üí aplicar filtro
    if parsed["entities"]:
        entity_ids = [e["entity_id"] for e in parsed["entities"]]
        entity_filter = Filter("entities").contains_any(entity_ids)
    else:
        entity_filter = None
    
    # 3. Se tem conceitos sem√¢nticos ‚Üí busca vetorial
    search_query = " ".join(parsed["semantic_terms"]) if parsed["semantic_terms"] else query
    query_vector = embedding_model.encode(search_query)
    
    # 4. Executa busca combinada
    chunks = await weaviate_manager.hybrid_search(
        vector=query_vector,
        entity_filter=entity_filter,
        alpha=0.6
    )
    
    return chunks
```

---

## ‚úÖ **Resumo: Como o Sistema Sabe**

| Aspecto | Como Funciona |
|---------|---------------|
| **Detec√ß√£o de Entidades** | spaCy NER + POS tagging |
| **Detec√ß√£o de Conceitos** | An√°lise POS (NOUN, ADJ) + Dependency parsing |
| **Classifica√ß√£o de Intent** | Pattern matching + POS structure |
| **Lookup** | Gazetteer fuzzy matching |
| **Combina√ß√£o** | H√≠brido: WHERE filter + Vector search |

**Exemplo Final:**

```
Query: "qual √© a estrat√©gia de inova√ß√£o da Apple?"
       ‚îú‚îÄ Entidade: "Apple" (ORG) ‚Üí entity_filter = WHERE entities = "Q123"
       ‚îú‚îÄ Conceitos: "estrat√©gia", "inova√ß√£o" ‚Üí semantic_search
       ‚îú‚îÄ Intent: QUESTION
       ‚îî‚îÄ Busca combinada: chunks sobre (Apple E estrat√©gia E inova√ß√£o)
```
