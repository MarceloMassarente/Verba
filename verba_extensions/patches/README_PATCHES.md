# üîß Patches e Hooks - Documenta√ß√£o para Upgrades do Verba

## ‚ö†Ô∏è IMPORTANTE: Ao Atualizar Verba

**ESTES S√ÉO PATCHES/MONKEY PATCHES** que modificam o comportamento do Verba core sem alterar o c√≥digo original.

Quando voc√™ atualizar o Verba, **verifique se estes patches ainda funcionam** e se precisam ser reaplicados.

---

## üìã Lista de Patches Aplicados

### 0. **Otimiza√ß√µes Fase 1 e 2** ‚≠ê‚≠ê CR√çTICA PARA PERFORMANCE

**Arquivos:** 
- `verba_extensions/integration/schema_updater.py` - √çndices
- `verba_extensions/utils/graphql_builder.py` - Parsers otimizados

**O que faz:**

**Fase 1: √çndices + Parser Otimizado**
- Adiciona `indexFilterable=True` a 6 fields cr√≠ticos
- Implementa `parse_entity_frequency()` - parser espec√≠fico para entidades
- Implementa `parse_document_stats()` - parser espec√≠fico para documentos
- Auto-detec√ß√£o de tipo de query (entity_frequency vs document_stats)

**Impacto Fase 1:**
- **-70% lat√™ncia** em hierarchical filtering queries
- **+40% usabilidade** em parsing (estrutura 90% mais acess√≠vel)
- **Zero overhead** - totalmente backward compatible

**Fase 2: Entity Source + Aggregation**
- Parametriza `entity_source` em `build_entity_aggregation()` ("local" | "section" | "both")
- Implementa `aggregate_entity_frequencies()` com pesos customiz√°veis
- Elimina redund√¢ncia de entidades automaticamente

**Impacto Fase 2:**
- **-50% tamanho** de resultado em aggregations (quando usa "local" ou "section")
- **+80% usabilidade** - sem necessidade de postprocessing no cliente
- **Zero redund√¢ncia** em entity aggregation (combina m√∫ltiplas fontes com pesos)

**Campos com √≠ndices adicionados:**
```python
# Propriedades Padr√£o
‚úÖ doc_uuid (indexFilterable=True) - hierarchical filtering
‚úÖ labels (indexFilterable=True) - document filtering
‚úÖ chunk_lang (indexFilterable=True) - bilingual filtering
‚úÖ chunk_date (indexFilterable=True) - temporal filtering

# Propriedades de ETL
‚úÖ entities_local_ids (indexFilterable=True) - entity filtering e agrega√ß√µes
‚úÖ primary_entity_id (indexFilterable=True) - entity filtering
```

**Como verificar ap√≥s upgrade:**
```python
from verba_extensions.integration.schema_updater import get_verba_standard_properties
props = get_verba_standard_properties()
for p in props:
    if hasattr(p, 'index_filterable') and p.index_filterable:
        print(f"‚úÖ {p.name} tem √≠ndice")
```

**Testes:** 5/5 testes passaram (pytest)

**Documenta√ß√£o completa:**
- `IMPLEMENTACAO_FASE1_FASE2_COMPLETA.md` - Implementa√ß√£o detalhada
- `RESUMO_IMPLEMENTACAO_COMPLETA.md` - Resumo r√°pido

---

### 1. **Schema ETL-Aware Universal** ‚≠ê NOVO - IMPORTANTE

**Arquivo:** `verba_extensions/integration/schema_updater.py`

**O que faz:**
- Patch em `WeaviateManager.verify_collection()` para criar collections com schema ETL-aware
- Schema inclui 20 propriedades: 13 padr√£o Verba + 7 ETL opcionais
- **Serve para AMBOS:** chunks normais (propriedades ETL vazias) e chunks ETL-aware (propriedades ETL preenchidas)
- Cria collections automaticamente com schema completo desde o in√≠cio

**Onde √© aplicado:**
- `verba_extensions/startup.py` linha ~57: Chama `patch_weaviate_manager_verify_collection()`
- Monkey patch: `managers.WeaviateManager.verify_collection = patched_verify_collection`

**Comportamento:**
1. Se collection existe ‚Üí Verifica se tem propriedades ETL
2. Se collection n√£o existe + √© VERBA_Embedding ‚Üí **Cria com schema ETL-aware completo**
3. Se collection n√£o existe + n√£o √© embedding ‚Üí Cria normalmente

**Propriedades criadas:**
- **Padr√£o Verba (13):** chunk_id, content, doc_uuid, title, labels, etc.
- **ETL (7 opcionais):** entities_local_ids, section_title, section_entity_ids, section_scope_confidence, primary_entity_id, entity_focus_score, etl_version

**Como verificar ap√≥s upgrade:**
```python
# 1. Verificar se patch est√° aplicado:
from verba_extensions.integration.schema_updater import patch_weaviate_manager_verify_collection
from goldenverba.components import managers
# Verificar se m√©todo foi substitu√≠do
if hasattr(managers.WeaviateManager, 'verify_collection'):
    print('‚úÖ verify_collection existe - patch pode ser aplicado')

# 2. Verificar se collection tem schema ETL:
from verba_extensions.integration.schema_updater import check_collection_has_etl_properties
has_etl = await check_collection_has_etl_properties(client, "VERBA_Embedding_all_MiniLM_L6_v2")
if has_etl:
    print('‚úÖ Schema ETL-aware')
else:
    print('‚ùå Schema padr√£o (sem ETL)')
```

**Se precisar reaplicar:**
- Patch √© aplicado automaticamente via `startup.py`
- Se n√£o funcionar, verificar se `WeaviateManager.verify_collection()` ainda existe
- Verificar se `client.collections.create()` ainda aceita par√¢metro `properties`

---

### 2. **ETL Pr√©-Chunking Hook** ‚úÖ

**Arquivo:** `verba_extensions/integration/chunking_hook.py`

**O que faz:**
- Extrai entidades do documento completo ANTES do chunking
- Permite chunking entity-aware que evita cortar entidades no meio
- Armazena `entity_spans` no `document.meta` para chunkers usarem

**Onde √© aplicado:**
- `goldenverba/verba_manager.py` linha ~241: Chama `apply_etl_pre_chunking()` antes do chunking

**Depend√™ncias:**
- `verba_extensions/plugins/a2_etl_hook.py` (fun√ß√µes de NER)
- spaCy instalado
- Gazetteer dispon√≠vel (opcional)

**Como verificar ap√≥s upgrade:**
```python
# Teste se ainda funciona:
from verba_extensions.integration.chunking_hook import apply_etl_pre_chunking
# Se importar sem erro, est√° OK
```

---

### 3. **Section-Aware Chunker Entity-Aware** ‚úÖ

**Arquivo:** `verba_extensions/plugins/section_aware_chunker.py`

**O que faz:**
- Modifica `SectionAwareChunker` para usar `entity_spans` pr√©-extra√≠dos
- Evita cortar entidades no meio durante chunking
- Mant√©m entidades completas no mesmo chunk

**Altera√ß√µes espec√≠ficas:**
- Linha ~135: L√™ `entity_spans` de `document.meta`
- Linha ~186-211: L√≥gica para evitar cortar entidades em se√ß√µes grandes
- Linha ~284-297: M√©todo `_chunk_by_sentences_entity_aware()` adicionado

**Como verificar ap√≥s upgrade:**
1. Verificar se `SectionAwareChunker.chunk()` ainda aceita documentos com `entity_spans`
2. Testar chunking de documento com entidades conhecidas

---

### 3.1. **Entity-Semantic Chunker** ‚≠ê NOVO - RECOMENDADO

**Arquivo:** `verba_extensions/plugins/entity_semantic_chunker.py`

**Status:** ‚úÖ Plugin registrado automaticamente via PluginManager

**O que faz:**
- **Chunker h√≠brido** que combina:
  1. **Section-aware**: Delimita por se√ß√µes (t√≠tulos/primeiro par√°grafo) para evitar contamina√ß√£o entre assuntos
  2. **Entity guardrails**: Usa `entity_spans` do ETL-PRE para n√£o cortar entidades no meio
  3. **Semantic breakpoints**: Quebras sem√¢nticas intra-se√ß√£o (reaproveita configs do SemanticChunker)
- **Ideal para artigos/URLs** que falam de m√∫ltiplas empresas
- **Configura√ß√£o padr√£o**: Usa "Entity-Semantic" como chunker padr√£o quando dispon√≠vel

**Caracter√≠sticas:**
- ‚úÖ **Reaproveita configs do SemanticChunker**: Breakpoint Percentile Threshold (80), Max Sentences Per Chunk (20)
- ‚úÖ **Overlap configur√°vel**: Em senten√ßas (padr√£o: 0)
- ‚úÖ **Fallback inteligente**: Se numpy/sklearn n√£o dispon√≠veis, usa cap por tamanho m√°ximo
- ‚úÖ **Compat√≠vel com ETL**: Usa `entity_spans` do ETL-PRE automaticamente

**Como funciona:**
1. Detecta se√ß√µes no documento (usa `detect_sections()` do SectionAwareChunker)
2. Para cada se√ß√£o:
   - Filtra senten√ßas dentro da se√ß√£o
   - Gera embeddings das senten√ßas (se dispon√≠vel)
   - Calcula breakpoints sem√¢nticos (cosine similarity drop)
   - Ajusta breakpoints para n√£o cortar entidades (usando `entity_spans`)
   - Aplica cap por tamanho m√°ximo (fallback)
3. Cria chunks respeitando limites de se√ß√£o + guard-rails de entidade + breakpoints sem√¢nticos

**Como √© registrado:**
- Plugin carregado automaticamente via `verba_extensions/startup.py`
- Registrado via `register()` que retorna `{'chunkers': [EntitySemanticChunker()]}`
- Adicionado aos chunkers dispon√≠veis via `PluginManager._hook_chunkers()`

**Como verificar ap√≥s upgrade:**
```python
# 1. Verificar se plugin est√° carregado:
from verba_extensions.plugin_manager import get_plugin_manager
pm = get_plugin_manager()
if 'entity_semantic_chunker' in pm.plugins:
    print('‚úÖ Entity-Semantic Chunker carregado')

# 2. Verificar se est√° dispon√≠vel no ChunkerManager:
from goldenverba.components import managers
if 'Entity-Semantic' in managers.chunkers:
    print('‚úÖ Entity-Semantic dispon√≠vel')

# 3. Verificar se √© padr√£o:
from goldenverba.verba_manager import VerbaManager
vm = VerbaManager()
config = vm.create_config()
if config['Chunker']['selected'] == 'Entity-Semantic':
    print('‚úÖ Entity-Semantic √© padr√£o')
```

**Se precisar reaplicar:**
- Plugin √© carregado automaticamente via `startup.py`
- Se n√£o aparecer, verificar se `verba_extensions/plugins/entity_semantic_chunker.py` existe
- Verificar se `register()` retorna estrutura correta
- Verificar se `PluginManager._hook_chunkers()` est√° sendo chamado

**Recomenda√ß√£o:**
- ‚≠ê **Use Entity-Semantic Chunker** para artigos/URLs com m√∫ltiplas empresas
- Combina o melhor dos tr√™s mundos: se√ß√µes + entidades + sem√¢ntica
- Evita contamina√ß√£o entre empresas mantendo chunks sem√¢nticamente coerentes

---

### 4. **Import Hook (ETL P√≥s-Chunking + Reconex√£o Autom√°tica)** ‚úÖ

**Arquivo:** `verba_extensions/integration/import_hook.py`

**O que faz:**
- Patch em `WeaviateManager.import_document()` para capturar `passage_uuids`
- Dispara ETL A2 ap√≥s importa√ß√£o dos chunks
- Mant√©m ETL p√≥s-chunking para section scope refinado
- **‚≠ê NOVO:** Reconex√£o autom√°tica do cliente Weaviate se fechado durante import longo

**Funcionalidades:**

1. **ETL P√≥s-Chunking:**
   - Captura `doc_uuid` ap√≥s import
   - Busca chunks importados por `doc_uuid`
   - Executa ETL A2 (NER + Section Scope) em background
   - N√£o bloqueia o processo de import

2. **Reconex√£o Autom√°tica (NOVO):**
   - Detecta quando cliente Weaviate est√° fechado ap√≥s import longo
   - Reconecta automaticamente usando credenciais do ambiente
   - Suporta Railway (WEAVIATE_HTTP_HOST) e outras configura√ß√µes
   - Retry at√© 3 vezes antes de desistir
   - Garante que ETL p√≥s-chunking seja executado mesmo ap√≥s desconex√µes

**Vari√°veis de ambiente usadas para reconex√£o:**
- `WEAVIATE_HTTP_HOST` (priorit√°rio para Railway)
- `WEAVIATE_URL_VERBA` (fallback)
- `WEAVIATE_API_KEY_VERBA`
- `WEAVIATE_PORT` ou `WEAVIATE_HTTP_PORT`
- `DEFAULT_DEPLOYMENT` (Custom, Weaviate, etc.)

**Como √© aplicado:**
- Chamado em `verba_extensions/startup.py` durante inicializa√ß√£o
- Monkey patch: `managers.WeaviateManager.import_document = patched_import_document`

**Comportamento:**
1. Durante import: Usa cliente normalmente
2. Ap√≥s import: Verifica se cliente est√° conectado
3. Se fechado: Tenta reconectar automaticamente
4. Se reconectar: Executa ETL p√≥s-chunking normalmente
5. Se falhar: Informa que chunks foram importados, mas ETL ser√° pulado

**Como verificar ap√≥s upgrade:**
```python
# Verificar se m√©todo ainda existe:
from goldenverba.components import managers
original_method = managers.WeaviateManager.import_document
# Se existir, patch pode ser reaplicado

# Verificar se reconex√£o funciona:
# 1. Importar documento grande (embedding longo)
# 2. Verificar logs: "[ETL-POST] ‚úÖ Reconectado automaticamente com sucesso"
# 3. Verificar se ETL p√≥s-chunking foi executado
```

---

### 4.1. **Client Cleanup Fix (Preven√ß√£o de "Client Closed" Durante Import)** ‚≠ê NOVO - CR√çTICO

**Arquivo:** `goldenverba/verba_manager.py` (modifica√ß√£o no core do Verba)

**Status:** ‚úÖ Implementado e testado

**O que faz:**
- **Corrige falha cr√≠tica**: Previne remo√ß√£o prematura de clientes Weaviate durante imports longos
- **Cleanup seguro**: Cleanup n√£o remove clientes ativos, apenas por timeout de inatividade
- **Auto-healing**: Tenta reconectar clientes que reportam n√£o estar prontos, ao inv√©s de remov√™-los
- **Reconex√£o autom√°tica**: Import tenta reconectar automaticamente se cliente fechar durante opera√ß√£o

**Problema resolvido:**
- **Antes**: Health check (`/api/health`) executava cleanup que removia clientes ativos durante embedding longo
- **Erro**: "The `WeaviateClient` is closed. Run `client.connect()` to (re)connect!" ap√≥s embedding bem-sucedido
- **Sintoma**: Import falhava imediatamente ap√≥s embedding completar (677 chunks gerados, mas import falhava)

**Mudan√ßas implementadas:**

1. **Cleanup Mais Conservador** (`ClientManager.clean_up()`):
   - ‚úÖ Timeout aumentado: 10 ‚Üí 60 minutos de inatividade
   - ‚úÖ N√£o remove por `is_ready() = False`: Apenas por timeout
   - ‚úÖ Auto-healing: Tenta reconectar antes de remover
   - ‚úÖ Touch timestamp: Atualiza timestamp ao reutilizar cliente

2. **Reconex√£o Autom√°tica no Import** (`VerbaManager.process_single_document()`):
   - ‚úÖ Verifica se cliente est√° pronto antes de importar
   - ‚úÖ Tenta reconectar cliente existente primeiro
   - ‚úÖ Se falhar, cria novo cliente a partir de vari√°veis de ambiente
   - ‚úÖ Continua com import ao inv√©s de abortar imediatamente

3. **Default Embedder Seguro** (`VerbaManager.create_config()`):
   - ‚úÖ Prefere `SentenceTransformers` como padr√£o quando dispon√≠vel
   - ‚úÖ Evita depend√™ncia de Ollama que pode n√£o estar rodando

**Como verificar ap√≥s upgrade:**
```python
from goldenverba import verba_manager

# Verificar timeout de cleanup
client_manager = verba_manager.ClientManager()
print(f"Cleanup timeout: {client_manager.max_time} minutos")  # Deve ser 60

# Verificar default embedder
vm = verba_manager.VerbaManager()
config = vm.create_config()
print(f"Default embedder: {config['Embedder']['selected']}")  # Deve ser SentenceTransformers se dispon√≠vel
```

**Logs esperados (ap√≥s fix):**
```
‚Ñπ Cleaning Clients Cache
‚Ñπ Client <hash> reported not ready during cleanup; attempting reconnect
‚úî Reconnected to Weaviate successfully
‚Ñπ 1 clients connected
‚úî Import for <document> completed successfully
```

**Se precisar reaplicar:**
- Este √© uma modifica√ß√£o no core do Verba (`goldenverba/verba_manager.py`)
- N√£o √© um patch/monkey patch, √© modifica√ß√£o direta
- Se atualizar Verba, pode precisar reaplicar estas mudan√ßas
- Verificar se m√©todos `ClientManager.clean_up()` e `VerbaManager.process_single_document()` ainda existem

**Refer√™ncias:**
- Documenta√ß√£o detalhada: `docs/troubleshooting/SOLUCAO_CLIENT_CLOSED_DURANTE_IMPORT.md`
- Data da corre√ß√£o: 2025-11-05

---

### 5. **ETL A2 Hook (NER + Section Scope)** ‚úÖ ‚≠ê ATUALIZADO

**Arquivo:** `verba_extensions/plugins/a2_etl_hook.py`  
**M√≥dulo ETL:** `ingestor/etl_a2_intelligent.py` ‚≠ê NOVO

**O que faz:**
- Executa ETL p√≥s-chunking: extrai entidades (NER) e determina section scope para cada chunk
- Atualiza chunks no Weaviate com propriedades ETL (`entity_mentions`, `entities_local_ids`, `section_entity_ids`, etc.)
- Fun√ß√£o principal: `run_etl_on_passages()` - chamada pelo import hook ap√≥s importa√ß√£o

**Funcionalidades:**
1. **NER Inteligente Multi-idioma (NOVO):**
   - Detecta idioma automaticamente (PT/EN) usando `langdetect`
   - Carrega modelo spaCy apropriado (`pt_core_news_sm` ou `en_core_web_sm`)
   - Extrai entidades SEM depender de gazetteer (modo inteligente)
   - Armazena em `entity_mentions` como JSON: `[{text, label, confidence}, ...]`
   - Fallback para gazetteer se dispon√≠vel (modo legado)

2. **Section Scope:**
   - Determina entidades relacionadas √† se√ß√£o baseado em t√≠tulo, primeiro par√°grafo e entidades pai
   - Armazena em `section_entity_ids` com n√≠vel de confian√ßa

3. **Suporte Universal a Embeddings:**
   - ‚úÖ Funciona com QUALQUER modelo de embedding (local ou API)
   - ‚úÖ Detecta collection automaticamente: `VERBA_Embedding_*`
   - ‚úÖ Recebe `collection_name` do hook para garantir collection correta
   - ‚úÖ Suporta: SentenceTransformers, OpenAI, Cohere, BGE, E5, Voyage AI, etc.

**Corre√ß√µes cr√≠ticas:**
- ‚ö†Ô∏è **CR√çTICO:** `coll.data.update()` √© ass√≠ncrono e DEVE ser aguardado com `await`
- ‚ö†Ô∏è **BUG CORRIGIDO:** ETL estava tentando atualizar collection `"Passage"` que n√£o existe
- ‚úÖ **CORRIGIDO:** Agora detecta collection correta (`VERBA_Embedding_*`) ou recebe via par√¢metro
- ‚úÖ **CORRIGIDO:** Hook passa `collection_name` explicitamente para ETL inteligente
- ‚úÖ **Atualiza√ß√£o 2025-11-08:** Orquestrador de queries (`entity_aware_query_orchestrator.py`) ganhou corre√ß√£o de idioma (PT ‚â† ES), heur√≠stica limitada (m√°x. 5 entidades / fallback s√≥ para queries curtas) e padr√µes mais ricos para sintaxe expl√≠cita; reduz falsos positivos sem explodir metadados nos chunks

**Como √© chamado:**
- Via hook `import.after` registrado em `verba_extensions/hooks.py`
- Disparado automaticamente ap√≥s `WeaviateManager.import_document()` (via import hook)
- Executa em background (n√£o bloqueia import)
- Recebe `collection_name` do embedder via `embedding_table`

**Como verificar ap√≥s upgrade:**
```python
# Verificar se fun√ß√£o ainda existe:
from verba_extensions.plugins.a2_etl_hook import run_etl_on_passages
from ingestor.etl_a2_intelligent import run_etl_patch_for_passage_uuids
# Se importar sem erro, est√° OK

# Verificar se collection_name √© passado:
# Linha ~162 deve ter: collection_name=collection_name
# ETL deve receber collection_name correto
```

**Erros comuns:**
- `RuntimeWarning: coroutine '_DataCollectionAsync.update' was never awaited`
  - **Solu√ß√£o:** Adicionar `await` antes de `coll.data.update()`
- Chunks n√£o t√™m propriedades ETL ap√≥s import
  - **Verificar:** Logs mostram "[ETL] Progresso: X/Y chunks atualizados..."
  - **Verificar:** `await` est√° presente na linha 256 de `etl_a2_intelligent.py`
  - **Verificar:** Collection correta est√° sendo usada (n√£o "Passage")
- ETL roda mas n√£o salva nada
  - **Causa:** Collection errada (estava usando "Passage")
  - **Solu√ß√£o:** Verificar se `collection_name` est√° sendo passado corretamente

---

### 6. **Query Builder + Entity-Aware Retriever** ‚úÖ ‚≠ê ATUALIZADO

**Arquivos:**
- `verba_extensions/plugins/query_builder.py`
- `verba_extensions/plugins/entity_aware_retriever.py`

**O que faz:**
- Garante que o **Query Builder** (LLM) e o **Entity-Aware Retriever** estejam totalmente alinhados com o novo ETL inteligente
- Permite usar **nomes diretos de entidades** (PERSON/ORG) sem necessidade de gazetteer ou IDs `ent:*`
- Usa entidade inteligente apenas para **PERSON** e **ORG** (evita polui√ß√£o com GPE/LOC/MISC)

**Funcionalidades principais:**
1. **Query Builder**
   - Prompt atualizado para instruir o LLM a retornar entidades como texto (ex.: `"Apple"`, `"Steve Jobs"`)
   - Fallback inteligente usa `extract_entities_from_query(..., use_gazetteer=False)`
   - Campos `filters.entities` e `filters.document_level_entities` aceitam textos diretos

2. **Entity-Aware Retriever**
   - Aceita entidades fornecidas pelo Query Builder (IDs `ent:*` **ou** textos)
   - Reutiliza textos para boost da busca e, quando apropriado, como filtro (`section_entity_ids`)
   - Mant√©m valida√ß√£o: somente PERSON/ORG s√£o utilizados para filtros

**Como verificar ap√≥s upgrade:**
```python
from verba_extensions.plugins.entity_aware_retriever import EntityAwareRetriever
from verba_extensions.plugins.query_builder import QueryBuilderPlugin

# EntityAwareRetriever deve aceitar textos do builder
# Checar bloco "if builder_entities" (~linhas 428-440) ‚Üí aceita strings sem prefixo "ent:"

# QueryBuilder fallback deve chamar extract_entities_from_query(..., use_gazetteer=False)
# e o prompt (docstring) deve instruir uso de nomes diretos
```

**Impacto esperado nos logs:**
```
‚Ñπ Query builder: entidades detectadas: ['Apple', 'Steve Jobs']
‚úÖ Query Builder forneceu textos de entidades: ['Apple', 'Steve Jobs']
‚úÖ Usando entidades para boostar busca: Apple Steve Jobs
‚úÖ Query com entidade expl√≠cita detectada, usando como filtro: ['Apple']
```

**Reaplica√ß√£o ap√≥s atualizar o Verba:**
- Se o Query Builder for sobrescrito por atualiza√ß√µes, reaplicar:
  - Prompt (se√ß√£o "IMPORTANTE") deve mencionar uso de textos diretos
  - Fallback deve usar `use_gazetteer=False`
- Se o Entity-Aware Retriever for substitu√≠do, reaplicar:
  - Bloco `if builder_entities` precisa aceitar listas de strings
  - Garantir que apenas PERSON/ORG sejam filtrados (consist√™ncia com ETL)

---

### 7. **Entity Filter Modes (Multi-Strategy Retrieval)** ‚úÖ ‚≠ê NOVO

**Arquivos:**
- `verba_extensions/plugins/entity_aware_retriever.py`

**Problema:**
- Filtro entity-aware era "tudo ou nada" (filtro duro ou desligado)
- Queries explorat√≥rias ("conceitos sobre inova√ß√£o") podiam perder contexto relevante se chunks n√£o tinham entidades
- Queries focadas ("sobre Apple") precisavam de filtro r√≠gido para evitar contamina√ß√£o

**Solu√ß√£o:**
Implementados **4 modos de filtro** configur√°veis:

1. **STRICT** (filtro duro)
   - Retorna APENAS chunks que cont√™m a entidade detectada
   - Uso: Queries focadas em entidade espec√≠fica ("resultados da Apple")
   - Risco: Pode n√£o encontrar contexto relevante se chunks n√£o t√™m entidade

2. **BOOST** (soft filter)
   - Busca TODOS os chunks, mas aplica boost de relev√¢ncia para chunks com entidade
   - Uso: Queries explorat√≥rias/conceituais ("conceitos de inova√ß√£o")
   - Risco: Pode trazer chunks de outras entidades (contamina√ß√£o)

3. **ADAPTIVE** (padr√£o recomendado) ‚≠ê
   - Come√ßa com STRICT, se encontrar <3 chunks, faz fallback para BOOST automaticamente
   - Uso: Uso geral - equilibra precis√£o e recall
   - Benef√≠cio: Sempre retorna contexto, adaptando-se ao conte√∫do dispon√≠vel

4. **HYBRID** (baseado em sintaxe)
   - Detecta padr√µes na query ("sobre Apple" ‚Üí STRICT, "inova√ß√£o disruptiva" ‚Üí BOOST)
   - Uso: Quando sintaxe da query indica claramente a inten√ß√£o
   - Padr√µes detectados: "sobre X", "da empresa Y", "X vs Y", queries curtas com entidade

**Configura√ß√£o:**
Na interface do Verba, nova op√ß√£o `Entity Filter Mode` com valores: `strict`, `boost`, `adaptive` (padr√£o), `hybrid`

**Logs esperados:**
```
üéØ Entity Filter Mode: adaptive
‚Ñπ Modo ADAPTIVE: tentar√° filtro STRICT com fallback para BOOST
‚Ñπ Executando: Hybrid search com filtros combinados
‚úÖ Encontrados 2 chunks
‚ö†Ô∏è ADAPTIVE FALLBACK: apenas 2 chunks com filtro strict, tentando modo BOOST...
‚úÖ ADAPTIVE FALLBACK: encontrados 8 chunks (vs 2 com filtro)
```

**Como reaplicar ap√≥s atualizar o Verba:**
1. Verificar se `config["Entity Filter Mode"]` existe no `__init__`
2. Verificar se m√©todo `_detect_entity_focus_in_query()` existe
3. Verificar se l√≥gica de busca (~linha 824-969) implementa os 4 modos

**Impacto:**
- Queries explorat√≥rias agora retornam contexto mesmo sem entidades exatas
- Queries focadas mant√™m precis√£o com filtro r√≠gido
- Sistema se adapta automaticamente ao conte√∫do dispon√≠vel (modo adaptive)

---

### 8. **Code-Switching Detector (PT + EN)** ‚úÖ ‚≠ê NOVO

**Arquivos:**
- `verba_extensions/utils/code_switching_detector.py`
- `verba_extensions/plugins/bilingual_filter.py`
- `ingestor/etl_a2_intelligent.py`
- `scripts/test_code_switching.py`

**Problema:**
- Documentos corporativos brasileiros misturam portugu√™s + jarg√£o financeiro em ingl√™s (cash flow, EBITDA, KPI...)
- Chunks marcados como `chunk_lang="pt"` n√£o eram retornados para queries em ingl√™s
- spaCy monol√≠ngue perdia entidades como "Apple", "Microsoft" quando chunk principal estava em PT

**Solu√ß√£o:**
- Detector de code-switching identifica textos com ‚â•12% de termos t√©cnicos EN ‚Üí classifica como `pt-en`
- ETL inteligente roda spaCy PT **e** EN no mesmo chunk (NER bil√≠ngue) com cache e deduplica√ß√£o
- `bilingual_filter` aceita automaticamente chunks `pt-en` quando query √© PT ou EN (filtro flex√≠vel)
- Script de teste `scripts/test_code_switching.py` valida 10 cen√°rios reais (80% de acerto)

**Como verificar ap√≥s upgrade:**
```python
from verba_extensions.utils.code_switching_detector import get_detector
detector = get_detector()
detector.detect_language_mix("O cash flow da empresa foi impactado pelo EBITDA")
# ‚ûú ('pt-en', {'technical_ratio': 0.28, ...})

from verba_extensions.plugins.bilingual_filter import BilingualFilterPlugin
plugin = BilingualFilterPlugin()
plugin.detect_query_language("How is the cash flow?")  # ‚ûú 'en-pt'
plugin.build_language_filter('en-pt')  # ‚ûú chunk_lang contains_any(['pt','en','pt-en','en-pt'])
```

**Logs esperados:**
```
‚Ñπ Chunk language detectado: pt-en (PT com jarg√£o EN)
‚Ñπ NER bil√≠ngue: spaCy pt_core_news_sm + en_core_web_sm
‚Ñπ Query builder: idioma detectado pt-en ‚Üí filtro aceita chunks bil√≠ngues
```

**Reaplica√ß√£o ap√≥s atualizar o Verba:**
- Garantir que `code_switching_detector.py` permane√ßa em `verba_extensions/utils`
- Verificar se `detect_text_language()` em `etl_a2_intelligent.py` retorna valores `pt-en`
- Confirmar que `build_language_filter()` usa `.contains_any([...])` em vez de `.equal()`
- Rodar `python scripts/test_code_switching.py` e verificar taxa de acerto ‚â•80%

**Impacto:**
- Queries em ingl√™s encontram chunks em PT com jarg√£o EN (e vice-versa)
- ETL extrai entidades globais (Apple, Microsoft) mesmo em texto portugu√™s
- Chunks marcados com `chunk_lang="pt-en"` evitam falsos negativos
- Experi√™ncia muito melhor em documentos financeiros/neg√≥cios

---

## üîÑ Processo de Reaplica√ß√£o Ap√≥s Upgrade

### **Passo 1: Verificar Compatibilidade**

```bash
# 1. Atualizar Verba
git pull origin main  # ou como voc√™ atualiza

# 2. Verificar se estrutura ainda existe
python -c "
from goldenverba.verba_manager import VerbaManager
from goldenverba.components.document import Document
print('‚úÖ Estruturas b√°sicas OK')
"

# 3. Verificar se hooks ainda funcionam
python -c "
from verba_extensions.integration.chunking_hook import apply_etl_pre_chunking
from verba_extensions.integration.import_hook import patch_weaviate_manager
print('‚úÖ Hooks OK')
"
```

### **Passo 2: Reaplicar Patches (se necess√°rio)**

Se algum patch falhar, verifique:

1. **ETL Pr√©-Chunking:**
   - Verificar se `verba_manager.py` ainda tem `process_single_document()`
   - Verificar se ainda aceita `document.meta`

2. **Schema ETL-Aware:**
   - Verificar se `WeaviateManager.verify_collection()` ainda existe
   - Verificar se `client.collections.create()` aceita par√¢metro `properties`
   - Verificar se `client.collections.exists()` ainda funciona

3. **Import Hook:**
   - Verificar se `WeaviateManager.import_document()` ainda existe
   - Verificar assinatura do m√©todo (par√¢metros mudaram?)

4. **Chunkers:**
   - Verificar se `SectionAwareChunker` ainda funciona
   - Verificar se `EntitySemanticChunker` plugin est√° carregado
   - Verificar se `document.meta` ainda √© acess√≠vel
   - Verificar se `detect_sections()` est√° dispon√≠vel (usado por EntitySemanticChunker)

### **Passo 3: Testar**

```bash
# Teste b√°sico: importar documento com ETL
# Deve ver logs:
# [ETL-PRE] ‚úÖ Entidades extra√≠das antes do chunking
# [ENTITY-AWARE] Usando X entidades pr√©-extra√≠das
# [ETL] ‚úÖ X chunks encontrados - executando ETL A2
```

---

## üìù Checklist de Upgrade

### Pr√©-Upgrade
- [ ] Backup do c√≥digo atual
- [ ] Backup do Weaviate (se necess√°rio)
- [ ] Documentar vers√£o atual do Verba

### Atualiza√ß√£o
- [ ] Atualizar Verba (git pull ou como voc√™ atualiza)
- [ ] Verificar imports b√°sicos funcionam
- [ ] Verificar se `verba_extensions/` foi copiado

### Verifica√ß√£o de Estrutura
- [ ] Verificar se `verba_manager.py` ainda tem `process_single_document()`
- [ ] Verificar se `WeaviateManager.verify_collection()` ainda existe
- [ ] Verificar se `WeaviateManager.import_document()` ainda existe
- [ ] Verificar se `SectionAwareChunker` ainda funciona
- [ ] Verificar se `client.collections.create()` aceita `properties`

### Verifica√ß√£o de Patches
- [ ] Verificar se `startup.py` est√° sendo chamado
- [ ] Verificar logs: "Patch de schema ETL-aware aplicado"
- [ ] Verificar logs: "Hook de integra√ß√£o ETL aplicado"
- [ ] Testar cria√ß√£o de collection: deve criar com schema ETL-aware
- [ ] Verificar se collection tem 20 propriedades (13 padr√£o + 7 ETL)

### ‚≠ê NOVO: Verifica√ß√£o de Otimiza√ß√µes Fase 1-2
- [ ] Verificar se `graphql_builder.py` tem `parse_entity_frequency()`
- [ ] Verificar se `graphql_builder.py` tem `parse_document_stats()`
- [ ] Verificar se `graphql_builder.py` tem `aggregate_entity_frequencies()`
- [ ] Verificar se `build_entity_aggregation()` aceita par√¢metro `entity_source`
- [ ] Verificar se 6 campos t√™m `index_filterable=True`
- [ ] Testar script: `python -m pytest scripts/test_phase1_phase2_optimizations.py -v`

### ‚≠ê NOVO: Verifica√ß√£o de Plugins
- [ ] Verificar se Google Drive Reader est√° carregado: `'google_drive_reader' in pm.plugins`
- [ ] Verificar se Google Drive Reader aparece na lista de readers: `'Google Drive (ETL A2)' in readers`
- [ ] Verificar se depend√™ncias Google Drive est√£o instaladas: `google-api-python-client`, `google-auth-httplib2`, `google-auth-oauthlib`
- [ ] Verificar se vari√°vel `GOOGLE_DRIVE_CREDENTIALS` est√° configurada (se usar Google Drive)

### Testes Funcionais
- [ ] Testar import de documento pequeno
- [ ] Verificar logs: "[ETL-PRE] ‚úÖ Entidades extra√≠das"
- [ ] Verificar logs: "[ENTITY-AWARE] Usando X entidades"
- [ ] Verificar logs: "[ETL-POST] ‚úÖ ETL executado"
- [ ] Verificar se chunks t√™m propriedades ETL (se ETL ativado)
- [ ] Testar busca com EntityAware Retriever
- [ ] Verificar se queries por entity_id funcionam
- [ ] Testar import do Google Drive (se configurado)

---

## üõ†Ô∏è Como Reaplicar Manualmente (se necess√°rio)

### **Patch 1: Schema ETL-Aware** ‚≠ê MAIS IMPORTANTE

**Local:** `verba_extensions/startup.py` (linha ~57)

**Na inicializa√ß√£o, chamar:**
```python
# Aplica patch de schema ETL (adiciona propriedades automaticamente)
try:
    from verba_extensions.integration.schema_updater import patch_weaviate_manager_verify_collection
    patch_weaviate_manager_verify_collection()
except Exception as e:
    msg.warn(f"Patch de schema ETL n√£o aplicado: {str(e)}")
```

**Este patch √© CR√çTICO** - sem ele, collections ser√£o criadas sem propriedades ETL e n√£o poder√£o ser atualizadas depois (Weaviate v4).

**Verificar se funcionou:**
- Ao criar collection, deve ver log: "Criando collection X com schema ETL-aware..."
- Collection deve ter 20 propriedades (verificar via `check_collection_has_etl_properties()`)

---

### **Patch 2: ETL Pr√©-Chunking**

**Local:** `goldenverba/verba_manager.py` (linha ~238-248)

**Antes do chunking, adicionar:**
```python
# FASE 1: ETL Pr√©-Chunking (extrai entidades do documento completo)
if enable_etl:
    try:
        from verba_extensions.integration.chunking_hook import apply_etl_pre_chunking
        document = apply_etl_pre_chunking(document, enable_etl=True)
        msg.info(f"[ETL-PRE] ‚úÖ Entidades extra√≠das antes do chunking")
    except Exception as e:
        msg.warn(f"[ETL-PRE] Erro (n√£o cr√≠tico): {str(e)}")
```

---

### **Patch 3: Import Hook**

**Local:** `verba_extensions/startup.py` (linha ~49)

**Na inicializa√ß√£o, chamar:**
```python
# Aplica hooks de integra√ß√£o (ETL)
try:
    from verba_extensions.integration.import_hook import patch_weaviate_manager, patch_verba_manager
    patch_weaviate_manager()  # Hook principal no WeaviateManager
    patch_verba_manager()  # Hook adicional se necess√°rio
except Exception as e:
    msg.warn(f"Hook de integra√ß√£o ETL n√£o aplicado: {str(e)}")
```

---

### **Patch 4: Chunker Entity-Aware**

**Local:** `verba_extensions/plugins/section_aware_chunker.py`

**No m√©todo `chunk()`, adicionar:**
```python
# Pega entidades pr√©-extra√≠das
entity_spans = []
if hasattr(document, 'meta') and document.meta:
    entity_spans = document.meta.get("entity_spans", [])
```

**No chunking de se√ß√µes grandes, adicionar l√≥gica para evitar cortar entidades.**

---

## üìö Arquivos Relacionados

### **Core (n√£o modificar diretamente):**
- `goldenverba/verba_manager.py` - Usa hook de ETL pr√©-chunking
- `goldenverba/components/managers.py` - Patchado via monkey patch

### **Extensions (nossos patches):**
- `verba_extensions/integration/schema_updater.py` - **Schema ETL-aware (CR√çTICO)**
- `verba_extensions/integration/chunking_hook.py` - ETL pr√©-chunking
- `verba_extensions/integration/import_hook.py` - ETL p√≥s-chunking
- `verba_extensions/plugins/section_aware_chunker.py` - Chunker entity-aware
- `verba_extensions/plugins/entity_semantic_chunker.py` - **Chunker h√≠brido (RECOMENDADO)** ‚≠ê NOVO
- `verba_extensions/plugins/a2_etl_hook.py` - Fun√ß√µes de NER (usado por ambos)

### **Startup:**
- `verba_extensions/startup.py` - Aplica patches na inicializa√ß√£o

---

## üîç Como Identificar se Precisa Reaplicar

### **Sintomas de que precisa reaplicar:**

1. **Erro: `ModuleNotFoundError: verba_extensions.integration.chunking_hook`**
   - ‚úÖ Arquivo existe? Verificar caminho
   - ‚úÖ Import est√° correto?

2. **Erro: `'VerbaManager' object has no attribute 'process_single_document'`**
   - ‚ö†Ô∏è M√©todo mudou de nome ou estrutura
   - ‚úÖ Verificar estrutura atual do VerbaManager

3. **Erro: `'WeaviateManager' object has no attribute 'import_document'`**
   - ‚ö†Ô∏è M√©todo mudou de nome ou estrutura
   - ‚úÖ Verificar estrutura atual do WeaviateManager

4. **Logs n√£o mostram `[ETL-PRE]`**
   - ‚ö†Ô∏è Hook n√£o est√° sendo chamado
   - ‚úÖ Verificar se `apply_etl_pre_chunking()` est√° sendo executado

5. **Chunks ainda cortam entidades no meio**
   - ‚ö†Ô∏è Chunker n√£o est√° usando `entity_spans`
   - ‚úÖ Verificar se `document.meta["entity_spans"]` est√° sendo lido

---

## üéØ Estrat√©gia de Upgrade Seguro

### **Op√ß√£o 1: Feature Flag (Recomendado)**

Adicionar flag para desabilitar patches se necess√°rio:

```python
# verba_extensions/startup.py
ENABLE_ETL_PRE_CHUNKING = os.getenv("ENABLE_ETL_PRE_CHUNKING", "true").lower() == "true"

if ENABLE_ETL_PRE_CHUNKING:
    # Aplica patches
    ...
```

### **Op√ß√£o 2: Version Check**

Verificar vers√£o do Verba antes de aplicar patches:

```python
# verba_extensions/startup.py
import goldenverba
verba_version = getattr(goldenverba, '__version__', 'unknown')

if verba_version.startswith('2.1'):
    # Patches compat√≠veis
    apply_patches()
else:
    msg.warn(f"Verba vers√£o {verba_version} - verificar compatibilidade dos patches")
```

---

## üìû Suporte

Se ap√≥s upgrade os patches n√£o funcionarem:

1. **Verificar logs** para erros espec√≠ficos
2. **Comparar estrutura** do Verba atual vs esperada
3. **Reaplicar patches** manualmente se necess√°rio
4. **Documentar mudan√ßas** encontradas para pr√≥xima vez

---

## ‚úÖ Status Atual

- ‚úÖ‚úÖ **Otimiza√ß√µes Fase 1 e 2**: Implementadas e testadas (5/5 testes) - **CR√çTICA PARA PERFORMANCE**
  - √çndices em 6 campos cr√≠ticos (-70% lat√™ncia)
  - Parsers otimizados (+40% usabilidade)
  - Entity source parametrizado (-50% tamanho)
  - Agrega√ß√£o de frequ√™ncias (-100% redund√¢ncia, +80% usabilidade)
- ‚úÖ **Schema ETL-Aware Universal**: Implementado e testado - **CR√çTICO**
  - Collections criadas automaticamente com schema completo (20 propriedades)
  - Serve para chunks normais E ETL-aware
  - Verifica√ß√£o autom√°tica na inicializa√ß√£o
- ‚úÖ **ETL Pr√©-Chunking**: Implementado e testado
- ‚úÖ **Section-Aware Chunker Entity-Aware**: Implementado e testado
- ‚úÖ **Entity-Semantic Chunker**: ‚≠ê NOVO - Implementado e configurado como padr√£o
  - Chunker h√≠brido: se√ß√µes + entidades + sem√¢ntica
  - Ideal para artigos/URLs com m√∫ltiplas empresas
  - Plugin registrado automaticamente
- ‚úÖ **Client Cleanup Fix**: ‚≠ê NOVO - Previne "Client Closed" durante imports longos
  - Cleanup seguro (60 min timeout, auto-healing)
  - Reconex√£o autom√°tica durante import
  - Default embedder seguro (SentenceTransformers)
- ‚úÖ **ETL P√≥s-Chunking Inteligente**: ‚≠ê ATUALIZADO - Multi-idioma, sem gazetteer obrigat√≥rio
  - Detec√ß√£o autom√°tica de idioma (PT/EN)
  - Extra√ß√£o de entidades sem gazetteer (modo inteligente)
  - Suporte universal a qualquer modelo de embedding (API ou local)
  - Corre√ß√£o cr√≠tica: collection correta (n√£o mais "Passage")
  - Salva `entity_mentions` em formato JSON
- ‚úÖ **RecursiveDocumentSplitter**: ‚≠ê REMOVIDO - Plugin redundante que expandia chunks desnecessariamente
  - Removido da lista de plugins carregados
  - Evita re-chunking desnecess√°rio (93 ‚Üí 2379 chunks)
  - Chunking inicial j√° √© bem feito, n√£o precisa re-otimizar
- ‚úÖ **Componentes RAG2**: Integrados (TelemetryMiddleware, Embeddings Cache, etc.)
- ‚úÖ **Google Drive Reader**: ‚≠ê NOVO - Plugin patchable para importa√ß√£o do Google Drive com ETL A2
  - Suporte a Service Account e OAuth 2.0
  - Importa√ß√£o recursiva de pastas
  - ETL A2 autom√°tico em todos os arquivos
- ‚úÖ **Documenta√ß√£o**: Este arquivo

**√öltima atualiza√ß√£o:** Novembro 2025  
**√öltima verifica√ß√£o de compatibilidade:** Verba 2.1.x (novembro 2024)  
**Mudan√ßas recentes:** Google Drive Reader, ETL inteligente multi-idioma, corre√ß√£o collection, suporte universal embeddings

---

## üÜï Componentes RAG2 Integrados (N√£o s√£o Patches)

Estes componentes N√ÉO s√£o patches (n√£o modificam c√≥digo do Verba), mas sim **extens√µes independentes** que podem ser usadas opcionalmente:

### **TelemetryMiddleware** ‚≠ê CR√çTICO

**Arquivo:** `verba_extensions/middleware/telemetry.py`

**Status:** ‚úÖ Implementado e pronto para uso

**O que faz:**
- Middleware FastAPI para observabilidade de API
- Registra lat√™ncia, contagem de requests e erros por endpoint
- Calcula percentis (p50, p95, p99) automaticamente
- Log estruturado em JSON
- SLO checking (verifica se p95 < threshold)

**Como usar:**
```python
# Em goldenverba/server/api.py
from verba_extensions.middleware.telemetry import TelemetryMiddleware

app.add_middleware(TelemetryMiddleware, enable_logging=True)
```

**N√£o precisa reaplicar ap√≥s upgrade:** √â c√≥digo independente, n√£o modifica Verba core.

**Documenta√ß√£o:** `GUIA_INTEGRACAO_RAG2_COMPONENTES.md`

---

### **Embeddings Cache** ‚≠ê CR√çTICO

**Arquivo:** `verba_extensions/utils/embeddings_cache.py`

**Status:** ‚úÖ Implementado e pronto para uso

**O que faz:**
- Cache in-memory determin√≠stico de embeddings
- Evita re-embedding de textos id√™nticos
- Reduz custo de APIs e melhora performance

**Como usar:**
```python
from verba_extensions.utils.embeddings_cache import get_cached_embedding, get_cache_key

cache_key = get_cache_key(text=chunk.text, doc_uuid=str(doc.uuid))
embedding, was_cached = get_cached_embedding(
    text=chunk.text,
    cache_key=cache_key,
    embed_fn=lambda t: self._call_embedding_api(t)
)
```

**N√£o precisa reaplicar ap√≥s upgrade:** √â c√≥digo independente, n√£o modifica Verba core.

**Documenta√ß√£o:** `GUIA_INTEGRACAO_RAG2_COMPONENTES.md`

---

### **Outros Componentes RAG2**

- **Telemetry Collector** (`verba_extensions/utils/telemetry.py`) - M√©tricas de ETL
- **UUID Determin√≠stico** (`verba_extensions/utils/uuid.py`) - Idempot√™ncia
- **Text Preprocessing** (`verba_extensions/utils/preprocess.py`) - Normaliza√ß√£o de texto
- **Quality Scoring** (`verba_extensions/utils/quality.py`) - Filtro de qualidade

**Documenta√ß√£o completa:** `ANALISE_RAG2_COMPONENTES_ALTO_VALOR.md` e `GUIA_INTEGRACAO_RAG2_COMPONENTES.md`

**Nota:** Estes componentes s√£o **opcionais** e **n√£o requerem patches**. Eles s√£o utilit√°rios que podem ser usados onde necess√°rio.

---

## üö® IMPORTANTE: Schema ETL-Aware

**O patch de schema √© CR√çTICO** porque:

1. **Weaviate v4 n√£o permite adicionar propriedades depois** que collection existe
2. **Collections criadas sem schema ETL** n√£o podem ser atualizadas
3. **Schema ETL-aware serve para ambos os casos:**
   - Chunks normais: propriedades ETL ficam vazias
   - Chunks ETL-aware: propriedades ETL s√£o preenchidas

**Ao atualizar Verba:**
1. ‚úÖ Verificar se `patch_weaviate_manager_verify_collection()` est√° sendo chamado
2. ‚úÖ Verificar logs: "Patch de schema ETL-aware aplicado"
3. ‚úÖ Testar cria√ß√£o de collection: deve criar com 20 propriedades
4. ‚úÖ Se collection existir sem ETL: deletar e recriar (ou usar script de migra√ß√£o)

**Documenta√ß√£o completa:** `SCHEMA_ETL_AWARE_UNIVERSAL.md`

---

### 6. **Tika Integration (Fallback + Reader + Universal Reader)** ‚≠ê NOVO

**Arquivos:**
- `verba_extensions/plugins/tika_reader.py` - Reader usando Tika
- `verba_extensions/integration/tika_fallback_patch.py` - Patch de fallback no BasicReader
- `verba_extensions/plugins/universal_reader.py` - Integra√ß√£o Tika no Universal Reader

**O que faz:**

**1. Tika Reader Plugin:**
- Adiciona um Reader que usa Apache Tika para extra√ß√£o
- Suporta 1000+ formatos (PDF, DOCX, PPTX, ODT, RTF, etc.)
- Extrai metadados automaticamente (autor, t√≠tulo, data, etc.)
- Configur√°vel via vari√°vel de ambiente `TIKA_SERVER_URL`

**2. Tika Fallback Patch:**
- Modifica `BasicReader.load_pdf_file()` para usar Tika quando m√©todo nativo falha
- Modifica `BasicReader.load_docx_file()` para usar Tika quando m√©todo nativo falha
- Modifica `BasicReader.load()` para usar Tika quando formato n√£o √© suportado
- Totalmente transparente - tenta m√©todo nativo primeiro, depois Tika

**3. Universal Reader Integration:**
- Universal Reader usa Tika diretamente para formatos ben√©ficos (PPTX, DOC, RTF, ODT, etc.)
- Extrai metadados automaticamente e passa para o ETL
- Fallback para BasicReader se Tika n√£o dispon√≠vel ou formato n√£o ben√©fico
- Configur√°vel via "Use Tika When Available" na UI

**Impacto:**
- ‚úÖ **PPTX funciona** (estava listado mas n√£o implementado)
- ‚úÖ **PDFs complexos** s√£o extra√≠dos corretamente
- ‚úÖ **Formatos antigos** (DOC, RTF, ODT) passam a funcionar
- ‚úÖ **Metadados** s√£o extra√≠dos automaticamente e dispon√≠veis para ETL
- ‚úÖ **Zero breaking changes** - m√©todos nativos t√™m prioridade
- ‚úÖ **Universal Reader melhorado** - usa Tika quando dispon√≠vel para melhor extra√ß√£o

**Como funciona:**
```python
# Fluxo Universal Reader com Tika:
1. Usu√°rio importa PPTX via Universal Reader
2. Universal Reader detecta PPTX ‚Üí usa Tika diretamente
3. Extrai texto + metadados (36+ campos)
4. Cria documento com metadados em doc.meta
5. ETL processa chunks com metadados dispon√≠veis

# Fluxo Fallback (se Universal Reader n√£o usar Tika):
1. BasicReader tenta m√©todo nativo
2. Se falhar OU formato n√£o suportado ‚Üí usa Tika automaticamente
3. Documento extra√≠do com sucesso
```

**Configura√ß√£o:**
```bash
# Vari√°vel de ambiente
export TIKA_SERVER_URL="http://192.168.1.197:9998"
```

**Verifica√ß√£o:**
- Verifica se servidor Tika est√° acess√≠vel em `TIKA_SERVER_URL`
- Se n√£o dispon√≠vel, m√©todos nativos continuam funcionando normalmente
- Patch s√≥ aplica se Tika estiver dispon√≠vel
- Universal Reader detecta Tika automaticamente

**Ao atualizar Verba:**
- ‚úÖ Verificar se `BasicReader.load()`, `load_pdf_file()`, `load_docx_file()` ainda existem
- ‚úÖ Se assinaturas mudarem, atualizar `tika_fallback_patch.py`
- ‚úÖ Verificar se `UniversalReader.load()` ainda funciona (pode ter mudado)
- ‚úÖ Testar com PPTX ou formato n√£o suportado para verificar fallback

**Onde √© aplicado:**
- `verba_extensions/startup.py` linha ~62: Chama `patch_basic_reader_with_tika_fallback()`
- Monkey patch: `BasicReader.load* = patched_load*`
- Universal Reader: integra√ß√£o direta no c√≥digo

**Documenta√ß√£o completa:** `INTEGRACAO_TIKA.md`

---

### 9. **Google Drive Reader (ETL A2 Integrado)** ‚≠ê NOVO

**Arquivo:** `verba_extensions/plugins/google_drive_reader.py`

**Status:** ‚úÖ Plugin patchable - carregado automaticamente

**O que faz:**
- Importa arquivos diretamente do Google Drive para o Verba
- Suporta Service Account e OAuth 2.0 para autentica√ß√£o
- Lista arquivos de pastas/compartilhamentos do Google Drive
- Baixa arquivos automaticamente e processa com BasicReader
- **ETL A2 autom√°tico** - Aplica NER + Section Scope em todos os arquivos importados
- Suporte recursivo a subpastas
- M√∫ltiplos formatos (PDF, DOCX, TXT, MD, XLSX, PPTX, etc.)

**Funcionalidades:**
1. **Autentica√ß√£o Flex√≠vel:**
   - Service Account (recomendado para servidores)
   - OAuth 2.0 (para contas pessoais)
   - Configura√ß√£o via vari√°vel de ambiente `GOOGLE_DRIVE_CREDENTIALS`

2. **Importa√ß√£o Inteligente:**
   - Importa por Folder ID ou URL compartilhada
   - Importa arquivos espec√≠ficos por File ID
   - Filtro por tipo de arquivo (PDF, DOCX, etc.)
   - Suporte recursivo a subpastas

3. **ETL A2 Integrado:**
   - Habilita ETL automaticamente em todos os documentos (`enable_etl=True`)
   - Extra√ß√£o de entidades (NER) e Section Scope
   - Metadados do Google Drive preservados (file_id, source, etc.)

**Depend√™ncias:**
- `google-api-python-client>=2.100.0`
- `google-auth-httplib2>=0.1.1`
- `google-auth-oauthlib>=1.1.0`

**Configura√ß√£o:**
```bash
# Service Account (recomendado)
export GOOGLE_DRIVE_CREDENTIALS="/caminho/para/service-account-key.json"

# OAuth 2.0 (alternativa)
export GOOGLE_DRIVE_CREDENTIALS="/caminho/para/token.json"
```

**Como √© registrado:**
- Plugin carregado automaticamente via `verba_extensions/startup.py`
- Registrado via `register()` que retorna `{'readers': [GoogleDriveReader()]}`
- Adicionado aos readers dispon√≠veis via `PluginManager._hook_readers()`
- Aparece na interface como tipo "URL"

**Como verificar ap√≥s upgrade:**
```python
# 1. Verificar se plugin est√° carregado:
from verba_extensions.plugin_manager import get_plugin_manager
pm = get_plugin_manager()
if 'google_drive_reader' in pm.plugins:
    print('‚úÖ Google Drive Reader carregado')

# 2. Verificar se est√° dispon√≠vel no ReaderManager:
from goldenverba.components import managers
readers = [r.name for r in managers.readers]
if 'Google Drive (ETL A2)' in readers:
    print('‚úÖ Google Drive Reader dispon√≠vel')

# 3. Verificar depend√™ncias:
try:
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    print('‚úÖ Depend√™ncias Google Drive instaladas')
except ImportError:
    print('‚ùå Depend√™ncias n√£o instaladas')
```

**Se precisar reaplicar:**
- Plugin √© carregado automaticamente via `startup.py`
- Se n√£o aparecer, verificar se `verba_extensions/plugins/google_drive_reader.py` existe
- Verificar se `register()` retorna estrutura correta
- Verificar se `PluginManager._hook_readers()` est√° sendo chamado
- Verificar se depend√™ncias est√£o instaladas no Dockerfile/requirements

**Documenta√ß√£o completa:** `verba_extensions/plugins/GOOGLE_DRIVE_README.md`

**Script de autentica√ß√£o:** `verba_extensions/plugins/google_drive_auth.py`

---

