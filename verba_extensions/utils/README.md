# üõ†Ô∏è Utility Modules

Utilit√°rios de alto valor e baixa complexidade copiados do RAG2 para melhorar observabilidade, performance e qualidade do Verba.

## üìã Componentes

### 1. Embeddings Cache ‚≠ê CR√çTICO

**Arquivo:** `embeddings_cache.py`

**Descri√ß√£o:**
Cache in-memory determin√≠stico de embeddings para evitar re-embedding redundante. Reduz drasticamente chamadas de APIs de embedding e melhora performance.

**Caracter√≠sticas:**
- ‚úÖ Cache determin√≠stico baseado em hash do texto
- ‚úÖ Estat√≠sticas de hit rate
- ‚úÖ Thread-safe (cache global compartilhado)
- ‚úÖ Opcional (pode ser desabilitado)

**Uso:**

```python
from verba_extensions.utils.embeddings_cache import (
    get_cached_embedding,
    get_cache_key,
    get_cache_stats,
    clear_cache
)

# Gerar chave de cache
cache_key = get_cache_key(
    text=chunk.text,
    doc_uuid=str(doc.uuid),
    parent_type="chunk"
)

# Obter embedding com cache
embedding, was_cached = get_cached_embedding(
    text=chunk.text,
    cache_key=cache_key,
    embed_fn=lambda t: self._call_embedding_api(t),
    enable_cache=True
)

# Verificar estat√≠sticas
stats = get_cache_stats()
print(f"Hit rate: {stats['hit_rate']:.2f}%")
```

**Impacto esperado:**
- Redu√ß√£o de 50-90% em chamadas de embedding em re-uploads
- Economia de custo de APIs (OpenAI, Cohere, etc.)
- Melhoria de performance (especialmente em processamento batch)

---

### 2. Telemetry Collector

**Arquivo:** `telemetry.py`

**Descri√ß√£o:**
Coletor de telemetria para m√©tricas de normaliza√ß√£o e cobertura. Identifica gaps em mapeamentos e gera relat√≥rios para melhoria cont√≠nua.

**Caracter√≠sticas:**
- ‚úÖ Rastreia m√©todos de normaliza√ß√£o (t√≠tulos, skills, companies)
- ‚úÖ Identifica termos n√£o mapeados (gaps)
- ‚úÖ Gera relat√≥rios JSON
- ‚úÖ Estat√≠sticas de qualidade de chunks

**Uso:**

```python
from verba_extensions.utils.telemetry import get_telemetry

telemetry = get_telemetry()

# Registrar normaliza√ß√£o de t√≠tulo
telemetry.record_title_normalization(
    method="regex",  # ou "llm", "none", etc.
    original_title="CEO"
)

# Registrar skill n√£o mapeada
telemetry.record_skill_normalization(
    was_mapped=False,
    original_skill="Python"
)

# Registrar chunk filtrado por qualidade
telemetry.record_chunk_filtered_by_quality(
    parent_type="section",
    score=0.25,
    reason="LEN_V_SHORT:DENSITY_LOW"
)

# Gerar relat√≥rio
report = telemetry.generate_report()
telemetry.save_report("telemetry_report.json")
```

**Relat√≥rio inclui:**
- Cobertura de normaliza√ß√£o de t√≠tulos por m√©todo
- Top 20 termos n√£o mapeados
- Distribui√ß√£o de proveni√™ncia de company_id
- Estat√≠sticas de chunks filtrados por qualidade

---

### 3. UUID Determin√≠stico

**Arquivo:** `uuid.py`

**Descri√ß√£o:**
Gera UUIDs determin√≠sticos (UUID v5) para garantir idempot√™ncia em re-uploads e upserts seguros.

**Caracter√≠sticas:**
- ‚úÖ UUID v5 baseado em namespace + identificador
- ‚úÖ Determin√≠stico: mesmo input = mesmo UUID
- ‚úÖ Idempot√™ncia garantida

**Uso:**

```python
from verba_extensions.utils.uuid import (
    generate_doc_uuid,
    generate_chunk_uuid,
    generate_chunk_uuid_by_type
)

# UUID para documento
doc_uuid = generate_doc_uuid(
    source_url=doc.meta.get("source_url"),
    public_identifier=doc.meta.get("public_id"),
    title=doc.title
)

# UUID para chunk
chunk_uuid = generate_chunk_uuid(
    doc_uuid=doc_uuid,
    chunk_id=f"{doc_uuid}:{chunk.chunk_id}"
)

# UUID para chunk com tipo (m√∫ltiplos vetores)
role_uuid = generate_chunk_uuid_by_type(
    doc_uuid=doc_uuid,
    vec_type="role",
    chunk_id=f"{doc_uuid}:{chunk.chunk_id}"
)
```

**Benef√≠cios:**
- Re-uploads n√£o criam duplicatas
- Upsert seguro (mesmo documento sempre tem mesmo UUID)
- Idempot√™ncia garantida

---

### 4. Text Preprocessing

**Arquivo:** `preprocess.py`

**Descri√ß√£o:**
Utilit√°rios para pr√©-processamento consistente de texto antes de embedding. Garante que texto embeddado √© id√™ntico ao texto armazenado.

**Caracter√≠sticas:**
- ‚úÖ Remove unicode invis√≠vel (zero-width spaces, etc.)
- ‚úÖ Normaliza whitespace
- ‚úÖ Truncamento sem√¢ntico (preserva boundaries naturais)
- ‚úÖ Valida√ß√£o de consist√™ncia

**Uso:**

```python
from verba_extensions.utils.preprocess import (
    prepare_for_embedding,
    validate_text_for_embedding,
    truncate_semantic
)

# Normalizar texto antes de embedding
text_for_embedding = prepare_for_embedding(chunk.text)

# Garantir consist√™ncia
is_valid, error = validate_text_for_embedding(
    text_stored=chunk.text,
    text_embedded=text_for_embedding
)

# Truncar semanticamente (preserva senten√ßas)
truncated = truncate_semantic(
    text="Texto muito longo...",
    max_chars=200,
    ellipsis="‚Ä¶"
)
```

**Benef√≠cios:**
- Consist√™ncia entre texto armazenado e embeddado
- Melhor qualidade de embeddings (texto normalizado)
- Evita problemas de encoding

---

### 5. Quality Scoring

**Arquivo:** `quality.py`

**Descri√ß√£o:**
Calcula score de qualidade de chunks para filtrar conte√∫do de baixa qualidade automaticamente.

**Caracter√≠sticas:**
- ‚úÖ Score de 0.0 a 1.0
- ‚úÖ Type-aware (diferentes thresholds por tipo)
- ‚úÖ Prote√ß√£o de summaries (nunca descartados)
- ‚úÖ Detec√ß√£o de login walls e placeholders

**Uso:**

```python
from verba_extensions.utils.quality import compute_quality_score

# Calcular score
score, reason = compute_quality_score(
    text=chunk.text,
    parent_type=chunk.meta.get("parent_type"),
    is_summary=chunk.meta.get("is_summary", False)
)

# Filtrar chunks de baixa qualidade
if score < 0.3:  # Threshold configur√°vel
    # Opcional: registrar na telemetria
    from verba_extensions.utils.telemetry import get_telemetry
    get_telemetry().record_chunk_filtered_by_quality(
        parent_type=chunk.meta.get("parent_type", "unknown"),
        score=score,
        reason=reason
    )
    continue  # Pula chunk
```

**Fatores considerados:**
- Comprimento do texto (200-3000 chars ideal)
- Densidade alfanum√©rica (>= 0.55 ideal)
- Detec√ß√£o de login walls
- Detec√ß√£o de placeholders
- Type-aware boost (experi√™ncias curtas s√£o aceitas)

**Benef√≠cios:**
- Filtragem autom√°tica de conte√∫do de baixa qualidade
- Melhor qualidade de resultados de busca
- Redu√ß√£o de ru√≠do nos resultados

---

## üìä Compara√ß√£o de Componentes

| Componente | Impacto Performance | Impacto Qualidade | Impacto Observabilidade | Complexidade |
|------------|---------------------|-------------------|-------------------------|--------------|
| Embeddings Cache | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê | ‚≠ê‚≠ê |
| Telemetry Collector | ‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| UUID Determin√≠stico | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê |
| Text Preprocessing | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê |
| Quality Scoring | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê |

---

## üîó Documenta√ß√£o Relacionada

- `ANALISE_RAG2_COMPONENTES_ALTO_VALOR.md` - An√°lise detalhada dos componentes
- `GUIA_INTEGRACAO_RAG2_COMPONENTES.md` - Guia de integra√ß√£o passo a passo
- `README_EXTENSOES.md` - Documenta√ß√£o geral das extens√µes

---

## ‚úÖ Checklist de Integra√ß√£o

- [ ] Embeddings Cache integrado em embedders
- [ ] Text Preprocessing usado antes de embedding
- [ ] Quality Scoring usado em filtros (opcional)
- [ ] Telemetry Collector usado em plugins ETL (opcional)
- [ ] UUID Determin√≠stico usado em imports (opcional)
- [ ] Testes realizados em ambiente de desenvolvimento

---

## üìù Notas

- Todos os componentes s√£o **opcionais** e podem ser integrados gradualmente
- **Embeddings Cache** tem maior impacto em performance
- Componentes s√£o **independentes** - voc√™ pode usar apenas alguns
- **Sem depend√™ncias externas** - apenas bibliotecas padr√£o Python
- Componentes s√£o **thread-safe** quando necess√°rio

